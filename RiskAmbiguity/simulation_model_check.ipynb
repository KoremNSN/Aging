{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9283390",
   "metadata": {},
   "source": [
    "# Data Simulation and Model Comparison\n",
    "\n",
    "In this notebook, I will simulate data based on the risk and ambiguity task in the modeling qualitative data project.\n",
    "\n",
    "The goal is to compare the performance of a utility function and the Estimated Value model under different conditions, specifically varying the number of participants and the noise levels.\n",
    "\n",
    "In this version of the task, there are 84 trials with the following parameters:\n",
    "\n",
    "Values: 5, 8, 12, 25\n",
    "\n",
    "Risk: 0.25, 0.5, 0.75\n",
    "\n",
    "Ambiguity: 0, 0.24, 0.5, 0.74\n",
    "\n",
    "## Libraries Used in the Experiment\n",
    "\n",
    "First, we must import the necessary libraries for data manipulation, probabilistic programming, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843fb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations and array manipulation\n",
    "import scipy as sp  # For scientific and technical computing\n",
    "from scipy.special import expit  # For the sigmoid function, the choice function\n",
    "from scipy import stats  # To draw from a truncated normal disterbution\n",
    "\n",
    "# Probabilistic programming and Bayesian statistical modeling\n",
    "import pymc as pm  \n",
    "import arviz as az  \n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns  \n",
    "\n",
    "# Suppressing warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(\"pymc\")\n",
    "logger.propagate = False\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab1ffd",
   "metadata": {},
   "source": [
    "## Loading the Choices Dataset\n",
    "\n",
    "We will load a CSV file that contains all the possible choices for the task without responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6620ca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the CSV file into a pandas DataFrame\n",
    "# 'sim.csv' is the file that contains the dataset with all the different possible choices\n",
    "db = pd.read_csv('sim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3763a9",
   "metadata": {},
   "source": [
    "## Simulating Decision-Making Data\n",
    "\n",
    "Next, we define a function to simulate the decision-making data. \n",
    "\n",
    "This function generates risk and ambiguity attitudes, adds noise, and simulates choices based on these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f009396-6d75-4213-9981-4bbd0b82ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncertainty_att(α_true, β_true):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    \n",
    "    # Plot the histogram for α_true with the header \"Risk attitude\"\n",
    "    sns.histplot(α_true, bins=30, kde=True, ax=axes[0])\n",
    "    axes[0].set_title(\"Risk attitude\")\n",
    "    axes[0].set_xlabel(\"Risk attitude values\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "    \n",
    "    # Plot the histogram for β_true with the header \"Ambiguity attitudes\"\n",
    "    sns.histplot(β_true, bins=30, kde=True, ax=axes[1])\n",
    "    axes[1].set_title(\"Ambiguity attitudes\")\n",
    "    axes[1].set_xlabel(\"Ambiguity attitudes values\")\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a78d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate decision-making data\n",
    "def sim_data(n_subs=10, noise=0.00001, \n",
    "             a_a=4, a_b=7, \n",
    "             b_mean=0.65, b_sd=1, lower_bound=-1.4, upper_bound=1.4):\n",
    "    \"\"\"\n",
    "    Simulates decision-making data for a given number of subjects.\n",
    "\n",
    "    Parameters:\n",
    "    n_subs (int): Number of subjects to simulate.\n",
    "    noise (float): Standard deviation of noise to add to risk and ambiguity attitudes.\n",
    "    a_a (float): Alpha parameter for beta distribution to generate risk attitudes.\n",
    "    a_b (float): Beta parameter for beta distribution to generate risk attitudes.\n",
    "    b_mean (float): Mean for truncated normal distribution to generate ambiguity attitudes.\n",
    "    b_sd (float): Standard deviation for truncated normal distribution to generate ambiguity attitudes.\n",
    "    lower_bound (float): Lower bound for truncated normal distribution.\n",
    "    upper_bound (float): Upper bound for truncated normal distribution.\n",
    "\n",
    "    Returns:\n",
    "    simdata: pd.DataFrame, Simulated dataset.\n",
    "    sub_idx: np.ndarray, Array of subject indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate risk attitudes using a beta distribution and scale it to 0-2\n",
    "    α_part = np.random.beta(a_a, a_b, n_subs)\n",
    "    α_true = α_part * 2\n",
    "    \n",
    "    # Generate ambiguity attitudes using a truncated normal distribution\n",
    "    a, b = (lower_bound - b_mean) / b_sd, (upper_bound - b_mean) / b_sd\n",
    "    β_true = stats.truncnorm.rvs(a, b, loc=b_mean, scale=b_sd, size=n_subs)\n",
    "\n",
    "    # Create arrays of all the choices for each simulated participant\n",
    "    value = np.tile(np.array(db.value), n_subs)\n",
    "    risk = np.tile(np.array(db.risk), n_subs)\n",
    "    ambiguity = np.tile(np.array(db.ambiguity), n_subs)\n",
    " \n",
    "    # Define constant reference values\n",
    "    refValue = 5  # constant reference value\n",
    "    refProbability = 1  # constant reference probability\n",
    "    refAmbiguity = 0  # constant reference ambiguity\n",
    "\n",
    "    # Create arrays of reference values, replicated for each trial\n",
    "    refProbabilities = np.tile(refProbability, len(value))\n",
    "    refValue = np.tile(refValue, len(value))\n",
    "    refAmbiguities = np.tile(refAmbiguity, len(value))\n",
    "\n",
    "    # Repeat risk and ambiguity attitudes for each simulated participant\n",
    "    riskTol = np.repeat(α_true, len(risk) / n_subs)\n",
    "    ambTol = np.repeat(β_true, len(ambiguity) / n_subs)\n",
    "\n",
    "    # Add noise to risk and ambiguity attitudes\n",
    "    noise_dist_a = np.random.normal(loc=0, scale=noise, size=len(riskTol))\n",
    "    noise_dist_b = np.random.normal(loc=0, scale=noise, size=len(riskTol))\n",
    "    riskTol += noise_dist_a\n",
    "    ambTol += noise_dist_b\n",
    "\n",
    "    # Adjust values to stay within specified bounds\n",
    "    riskTol = np.clip(riskTol, 0.1, 1.6)\n",
    "    ambTol = np.clip(ambTol, -1.4, 1.4)\n",
    "\n",
    "    # Calculate utility for reference and lottery\n",
    "    uRef = refValue ** riskTol\n",
    "    uLotto = (value ** riskTol) * (risk - ambTol * (ambiguity / 2))\n",
    "    p = sp.special.expit(uLotto - uRef)  # Apply logistic function to calculate choice probabilities\n",
    "\n",
    "    # Simulate choices based on probabilities\n",
    "    choice = np.random.binomial(1, p, len(p))\n",
    "\n",
    "    # Create subject indices for each trial\n",
    "    sub_idx = np.repeat(np.arange(n_subs), 84)\n",
    "    ID = sub_idx + 1\n",
    "    \n",
    "    # Generate a DataFrame with the simulated data\n",
    "    simdata = pd.DataFrame({'sub': ID,\n",
    "                            'choice': choice,\n",
    "                            'value': value, \n",
    "                            'risk': risk, \n",
    "                            'ambiguity': ambiguity,\n",
    "                            'riskTol': riskTol,\n",
    "                            'ambTol': ambTol})\n",
    "\n",
    "    # Rank the value levels and create binary columns for each level\n",
    "    simdata['level'] = simdata['value'].rank(method='dense').astype(int)\n",
    "\n",
    "    simdata['l1'] = simdata.level > 0\n",
    "    simdata['l2'] = simdata.level > 1\n",
    "    simdata['l3'] = simdata.level > 2\n",
    "    simdata['l4'] = simdata.level > 3\n",
    "\n",
    "    simdata['l1'] = simdata['l1'].astype(int)\n",
    "    simdata['l2'] = simdata['l2'].astype(int)\n",
    "    simdata['l3'] = simdata['l3'].astype(int)\n",
    "    simdata['l4'] = simdata['l4'].astype(int)\n",
    "    \n",
    "    return simdata, sub_idx\n",
    "\n",
    "# Load the file with all different possible choices\n",
    "db = pd.read_csv('sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0224e2e6-8f68-468b-a629-35988590d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Utility(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    Estimate the utility function of the subjects using a model that accounts for both the value of an outcome \n",
    "    and the probability of its occurrence.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing data on choice, value levels, risk, and ambiguity for each trial.\n",
    "    - n_subs: Number of subjects in the dataset.\n",
    "    - idx: Subject index for each trial (used for modeling individual variations).\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the probabilistic model for utility function\n",
    "    with pm.Model() as Utility:\n",
    "        \n",
    "        # Hyperpriors define group-level distributions for subject-specific parameters.\n",
    "        alpha_a = pm.TruncatedNormal('alpha_a', 4, 1, lower = 0)  # Shape parameter for risk attitude\n",
    "        alpha_b = pm.TruncatedNormal('alpha_b', 7, 3, lower = 0)  # Rate parameter for risk attitude\n",
    "        bMu     = pm.Normal('bMu',   .65, 1)  # Group-level mean for ambiguity modulation\n",
    "\n",
    "        # Individual subject priors.\n",
    "        alpha = pm.Beta('alpha', alpha_a, alpha_b, shape = n_subs) # Subject-specific utility curvature\n",
    "        α     = pm.Deterministic('α', alpha * 2) # Scale the value of alpha\n",
    "        β     = pm.TruncatedNormal('β', bMu, 1, lower = -1.5, upper = 1.5, shape = n_subs) # Ambiguity modulation\n",
    "        γ     = pm.LogNormal('γ', 0, .25, shape = n_subs) # Inverse temperature parameter\n",
    "\n",
    "        # Calculate the expected value of the outcome using a power function.\n",
    "        value = df['value'].values ** α[idx]  # Subjective value based on curvature parameter\n",
    "        prob  = df['risk'].values  - (β[idx] * (df['ambiguity'].values/2))  # Probability of outcome considering ambiguity\n",
    "\n",
    "        # Calculate the subjective value (SV) of the lottery for each trial\n",
    "        svLotto = value * prob\n",
    "        svRef   = 5 ** α[idx]  # Reference value\n",
    "\n",
    "        # Convert SV into a probability of choosing the lottery using the inverse logit function.\n",
    "        p  = (svLotto - svRef) / γ[idx]\n",
    "        mu = pm.invlogit(p)\n",
    "\n",
    "        # Define the likelihood of observations using a Binomial distribution, as the choice is binary.\n",
    "        choice = pm.Binomial('choice', 1, mu, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "           \n",
    "    return(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34e945f-a310-4d25-a372-fff2cf7f1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_values_ordinal(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    Estimate the value of different reward levels using ordinal constraints and a common hyperprior for each level. \n",
    "    The model ensures that the levels are positive (ordinal constraints).\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with trial-specific details, such as choices, value levels, risk, and ambiguity levels.\n",
    "    - n_sub: Total number of subjects in the dataset.\n",
    "    - idx: A list indicating the subject ID for each observation/trial.\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    with pm.Model() as estimate:\n",
    "\n",
    "        # Hyperparameters for group-level distributions\n",
    "        bMu  = pm.Normal('bMu', .65, 1)     # Mean for ambiguity effect distribution\n",
    "\n",
    "        # Hyperparameters for group-level subjective value levels\n",
    "        l1Mu = pm.TruncatedNormal('l1Mu', 4, 2, lower=0)  # Mean for value of level 1\n",
    "        l2Mu = pm.TruncatedNormal('l2Mu', 4, 2, lower=0)  # ... level 2\n",
    "        l3Mu = pm.TruncatedNormal('l3Mu', 4, 2, lower=0)  # ... level 3\n",
    "        l4Mu = pm.TruncatedNormal('l4Mu', 4, 2, lower=0)  # ... level 4\n",
    "\n",
    "        \n",
    "        # Subject-specific priors \n",
    "        β = pm.Normal('β', bMu, 1, shape = n_subs)   # Modulation of ambiguity effect\n",
    "        γ = pm.Lognormal('γ', 0, 0.25, shape = n_subs)   # Inverse temperature, impacting choice stochasticity\n",
    "\n",
    "        # Priors for subjective values of the different reward levels for each subject.\n",
    "        level1 = pm.TruncatedNormal('level1', l1Mu, 1, lower = 0, shape = n_subs)\n",
    "        level2 = pm.TruncatedNormal('level2', l2Mu, 1, lower = 0, shape = n_subs)\n",
    "        level3 = pm.TruncatedNormal('level3', l3Mu, 1, lower = 0, shape = n_subs)\n",
    "        level4 = pm.TruncatedNormal('level4', l4Mu, 1, lower = 0, shape = n_subs)\n",
    "\n",
    "        # Calculate the total expected value for each trial by combining values from different levels\n",
    "        val = (df['l1'].values * level1[idx] + \n",
    "               df['l2'].values * level2[idx] + \n",
    "               df['l3'].values * level3[idx] + \n",
    "               df['l4'].values * level4[idx]) \n",
    "\n",
    "        # Calculate adjusted probability by considering both risk and ambiguity levels modulated by β\n",
    "        prob = (df['risk'].values) - (β[idx] * (df['ambiguity'].values/2))  \n",
    "\n",
    "        # Compute the subjective value of the lottery option\n",
    "        svLotto = val * prob\n",
    "        svRef   = level1[idx]  # The subjective value of the reference option\n",
    "\n",
    "        # Transform the SV difference between lottery and reference into a choice probability using the logistic function\n",
    "        p  = (svLotto - svRef) / γ[idx]\n",
    "        mu = pm.invlogit(p)\n",
    "\n",
    "        # Likelihood of the observed choices given the computed probabilities\n",
    "        choice = pm.Binomial('choice', 1, mu, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "        \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2c72a-b91b-493d-ba7c-fe7f519d8740",
   "metadata": {},
   "source": [
    "## Running Simulations and Model Comparisons\n",
    "\n",
    "We then run simulations for different numbers of participants and levels of noise. The results of the model comparisons are stored in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb120aab-680f-4f73-a890-ba8a1ab3eee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=30 and noise=0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53bff41b8c94a8e97d4679a3ab1827a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ecf3e2d6d348858668a8ce986a0738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=30 and noise=0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e204cf5f92a34b0b97637afd1e8492f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdc2f7a37264fdbb87f190fcffe1fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=30 and noise=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719057dab59040a69c6a4b2745a09460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71b1e25453e4c5db72b7f77561c5e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=60 and noise=0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8165cb733cc6488698f2aaf7686915a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dac8746ac5b4ef6825b9c677f46ca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=60 and noise=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32a0e37f83d47e5a351ae7287b7abc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ca6cff24ba48dba5a638129b87971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=120 and noise=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9a235c23174d9f86016c6654c326f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563127d557a54993a878c11cf9398bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with N=300 and noise=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfcd7a15a5604abe850e15738bb870e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f2e81be80641c887c5d7dac5697a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results = pd.DataFrame(columns=['N', 'noise', 'Comparison'])\n",
    "\n",
    "test = [(30, 0.1),(30, 0.3), (30, 0.5), (60, 0.3), (60, 0.5), (120, 0.5), (300, 0.5)]\n",
    "# Loop over different values of N and noise\n",
    "for SIM in test:\n",
    "    try:\n",
    "        N = SIM[0]\n",
    "        noise = SIM[1]\n",
    "        print(f\"Simulating with N={N} and noise={noise}\")\n",
    "        \n",
    "        sim, sim_idx = sim_data(N, noise=noise)\n",
    "        utility = Utility(sim, N, sim_idx)\n",
    "        estimated = estimate_values_ordinal(sim, N, sim_idx)\n",
    "        \n",
    "        comp = az.compare({\n",
    "            'Classic Utility': utility,\n",
    "            'Estimated values': estimated})\n",
    "\n",
    "        # Save the results to the DataFrame \n",
    "        new_row = pd.DataFrame({'N': [N], 'noise': [noise], 'Comparison': [comp]})\n",
    "        results = pd.concat([results, new_row], ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Simulation failed for N={N} and noise={noise}. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc61e3-130f-4632-be05-c2cf683522ac",
   "metadata": {},
   "source": [
    "## Printing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e968909-d456-4ce9-a044-a71c604675c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 30, noise: 0.1\n",
      "Comparison outcome:\n",
      "                  rank     elpd_loo      p_loo  elpd_diff    weight  \\\n",
      "Classic Utility      0 -1237.291188  59.220923   0.000000  0.928588   \n",
      "Estimated values     1 -1277.650057  78.840682  40.358868  0.071412   \n",
      "\n",
      "                         se       dse  warning scale  \n",
      "Classic Utility   26.289285  0.000000     True   log  \n",
      "Estimated values  25.053221  9.241349    False   log  \n",
      "\n",
      "\n",
      "N: 30, noise: 0.3\n",
      "Comparison outcome:\n",
      "                  rank     elpd_loo      p_loo  elpd_diff    weight  \\\n",
      "Classic Utility      0 -1404.250915  68.661170   0.000000  0.671807   \n",
      "Estimated values     1 -1410.299069  84.274184   6.048153  0.328193   \n",
      "\n",
      "                         se       dse  warning scale  \n",
      "Classic Utility   25.758849  0.000000     True   log  \n",
      "Estimated values  23.564797  9.048145    False   log  \n",
      "\n",
      "\n",
      "N: 30, noise: 0.5\n",
      "Comparison outcome:\n",
      "                  rank     elpd_loo      p_loo  elpd_diff    weight  \\\n",
      "Estimated values     0 -1432.324020  89.450778   0.000000  0.692139   \n",
      "Classic Utility      1 -1450.721192  76.544238  18.397173  0.307861   \n",
      "\n",
      "                         se       dse  warning scale  \n",
      "Estimated values  24.103858  0.000000    False   log  \n",
      "Classic Utility   26.508309  9.767965     True   log  \n",
      "\n",
      "\n",
      "N: 60, noise: 0.3\n",
      "Comparison outcome:\n",
      "                  rank     elpd_loo       p_loo  elpd_diff    weight  \\\n",
      "Classic Utility      0 -2627.002920  138.387949   0.000000  0.716684   \n",
      "Estimated values     1 -2651.238098  167.315226  24.235178  0.283316   \n",
      "\n",
      "                         se        dse  warning scale  \n",
      "Classic Utility   38.046932   0.000000     True   log  \n",
      "Estimated values  35.003613  13.670736    False   log  \n",
      "\n",
      "\n",
      "N: 60, noise: 0.5\n",
      "Comparison outcome:\n",
      "                  rank     elpd_loo       p_loo  elpd_diff    weight  \\\n",
      "Estimated values     0 -2861.485957  170.906927   0.000000  0.557528   \n",
      "Classic Utility      1 -2880.080205  141.843674  18.594248  0.442472   \n",
      "\n",
      "                         se        dse  warning scale  \n",
      "Estimated values  32.974130   0.000000    False   log  \n",
      "Classic Utility   37.500829  14.384825     True   log  \n",
      "\n",
      "\n",
      "N: 120, noise: 0.5\n",
      "Comparison outcome:\n",
      "                  rank     elpd_loo       p_loo  elpd_diff  weight         se  \\\n",
      "Estimated values     0 -5692.973006  352.796602   0.000000  0.5727  48.470654   \n",
      "Classic Utility      1 -5720.478679  294.016802  27.505673  0.4273  53.050002   \n",
      "\n",
      "                        dse  warning scale  \n",
      "Estimated values   0.000000    False   log  \n",
      "Classic Utility   17.498575     True   log  \n",
      "\n",
      "\n",
      "N: 300, noise: 0.5\n",
      "Comparison outcome:\n",
      "                  rank      elpd_loo       p_loo  elpd_diff    weight  \\\n",
      "Estimated values     0 -14602.902842  856.226808    0.00000  0.628687   \n",
      "Classic Utility      1 -14695.346761  693.877811   92.44392  0.371313   \n",
      "\n",
      "                         se        dse  warning scale  \n",
      "Estimated values  73.116745   0.000000    False   log  \n",
      "Classic Utility   80.538540  25.817223     True   log  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results)):\n",
    "    # Print the values of N and noise for the current row\n",
    "    print(f\"N: {results['N'][i]}, noise: {results['noise'][i]}\")\n",
    "    # Print the comparison outcome for the current row\n",
    "    print(\"Comparison outcome:\")\n",
    "    print(results['Comparison'][i])\n",
    "    print(\"\\n\")  # Print a newline for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa01a2-016f-4e70-aaff-6b0b712e0c7a",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "In the simulations, the performance of the two models—<b>Classic Utility</b> and <b>Estimated Value</b>—was compared across different combinations of the number of participants (N) and noise levels.\n",
    "\n",
    "<ul>\n",
    "  <li><b>N: 30, noise: 0.1</b>\n",
    "    <ul>\n",
    "      <li>Classic Utility model fits better, with a higher <i>elpd_loo</i> and a weight of 0.9286.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><b>N: 30, noise: 0.3</b>\n",
    "    <ul>\n",
    "      <li>Classic Utility model still fits better, but the difference between the models is smaller. Classic Utility weight: 0.6718.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><b>N: 30, noise: 0.5</b>\n",
    "    <ul>\n",
    "      <li>Estimated Values model starts to outperform the Classic Utility model with a higher <i>elpd_loo</i> and a weight of 0.6921.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><b>N: 60, noise: 0.3</b>\n",
    "    <ul>\n",
    "      <li>Classic Utility model fits better, but the difference is reduced compared to lower noise levels. Classic Utility weight: 0.7167.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><b>N: 60, noise: 0.5</b>\n",
    "    <ul>\n",
    "      <li>Estimated Values model fits better again, indicating its robustness in higher noise. Estimated Values weight: 0.5575.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><b>N: 120, noise: 0.5</b>\n",
    "    <ul>\n",
    "      <li>Estimated Values model continues to outperform the Classic Utility model. Estimated Values weight: 0.5727.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li><b>N: 300, noise: 0.5</b>\n",
    "    <ul>\n",
    "      <li>Estimated Values model has a significant advantage over the Classic Utility model with a substantial <i>elpd_diff</i> and a weight of 0.6287.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "As the noise level increases, the <b>Estimated Values</b> model tends to perform better compared to the <b>Classic Utility</b> model. This suggests that the Estimated Values model is more robust to noise regardless of N size.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
