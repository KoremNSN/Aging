{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7142b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import scipy as sp\n",
    "\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79e5108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants monetary:  332 \n",
      "participants medical:  332\n"
     ]
    }
   ],
   "source": [
    "db_mon = pd.read_csv('data_online/mon_clean.csv')\n",
    "db_med = pd.read_csv('data_online/med_clean.csv')\n",
    "\n",
    "print('Participants monetary: ', len(db_mon['sub'].unique()), '\\nparticipants medical: ', len(db_med['sub'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd55fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique serial number for each participant.\n",
    "db_mon['subn'] = db_mon['sub'].rank(method='dense').astype(int) - 1\n",
    "\n",
    "# Count the number of unique subjects in the 'db_mon' dataset.\n",
    "n_subs = db_mon['subn'].unique().shape[0]\n",
    "\n",
    "# Create a list of subject indices for all rows in the 'db_mon' dataset.\n",
    "sub_idx = db_mon.subn.tolist()\n",
    "\n",
    "# Assign a unique serial number for each participant. This will be useful for indexing operations.\n",
    "db_med['subn'] = db_med['sub'].rank(method='dense').astype(int) - 1\n",
    "\n",
    "# Count the number of unique subjects in the 'db_med' dataset.\n",
    "n_subs_med = db_med['subn'].unique().shape[0]\n",
    "\n",
    "# Create a list of subject indices for all rows in the 'db_med' dataset.\n",
    "sub_idx_med = db_med.subn.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53879440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def straw_man(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    A simple model (straw man) that tries to estimate the influence of value, risk, and ambiguity \n",
    "    on the choice made by subjects in a gambling scenario.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing data on choice, value, risk, and ambiguity for each trial\n",
    "    - n_subs: Number of subjects in the study\n",
    "    - idx: Subject index for each trial (used for hierarchical modeling)\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    with pm.Model() as simple:  # Define a new PyMC3 model\n",
    "    \n",
    "        # Define hyperpriors for the group-level parameter (γ)\n",
    "        gMu = pm.Normal('gMu',  0, 1) # Mean of the normal distribution\n",
    "        gSig = pm.Gamma('gSig', 2, 1) # Standard deviation (Gamma distribution provides only positive values)\n",
    "\n",
    "        # Define the subject-specific risk preference (γ) using a lognormal distribution\n",
    "        γ = pm.Lognormal('γ', gMu, gSig, shape = n_subs)\n",
    "\n",
    "        # Compute expected value of the lottery outcome\n",
    "        val  = df['value'].values                                # Values from the 'value' column in the DataFrame\n",
    "        prob = df['risk'].values - (df['ambiguity'].values / 2)  # Probability calculation adjusted by ambiguity\n",
    "\n",
    "        svLotto = val * prob # Subjective value of the lottery\n",
    "        svRef   = 1          # Subjective value of a reference (assumed to be 1)\n",
    "        \n",
    "        # Define the linear predictor (p) and compute the expected probability (mu) using the inverse logit function\n",
    "        p  = (svLotto - svRef) / γ[idx]\n",
    "        mu =  pm.invlogit(p)                     # The invlogit function transforms values to the (0,1) interval\n",
    "\n",
    "        # Define the likelihood of the observed data. A binomial likelihood is chosen because the outcome is binary (choice is 0 or 1)\n",
    "        choice = pm.Binomial('choice', 1, mu, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "        \n",
    "    return(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebfd3cb-1644-4c08-86c3-902ebf2d9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Utility(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    Estimate the utility function of the subjects using a model that accounts for both the value of an outcome \n",
    "    and the probability of its occurrence.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing data on choice, value levels, risk, and ambiguity for each trial.\n",
    "    - n_subs: Number of subjects in the dataset.\n",
    "    - idx: Subject index for each trial (used for modeling individual variations).\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the probabilistic model for utility function\n",
    "    with pm.Model() as Utility:\n",
    "        \n",
    "        # Hyperpriors define group-level distributions for subject-specific parameters.\n",
    "        alpha_a = pm.Normal('alpha_a',  4,   1)  # Shape parameter for risk attitude\n",
    "        alpha_b = pm.Normal('alpha_b', 7,   3)  # Rate parameter for risk attitude\n",
    "        bMu     = pm.Normal('bMu',     .65, 1)  # Group-level mean for ambiguity modulation\n",
    "        bSig    = pm.Gamma('bSig',     4,   1)  # Group-level standard deviation for ambiguity modulation\n",
    "\n",
    "        # Individual subject priors.\n",
    "        alpha = pm.Beta('alpha',  alpha_a, alpha_b, shape = n_subs)                        # Subject-specific utility curvature\n",
    "        α = pm.Deterministic('α', alpha * 2)                                               # Double the value of alpha for further computations\n",
    "        β = pm.TruncatedNormal('β',  bMu, bSig, lower = -1.5, upper = 1.5, shape = n_subs) # Ambiguity modulation\n",
    "        γ = pm.LogNormal('γ', 0, .25, shape = n_subs)                                   # Inverse temperature parameter\n",
    "\n",
    "        # Calculate expected value of outcome using a power function.\n",
    "        value = df['value'].values ** α[idx]  # Subjective value based on curvature parameter\n",
    "        prob  = df['risk'].values  - (β[idx] * (df['ambiguity'].values/2))  # Probability of outcome considering ambiguity\n",
    "\n",
    "        # Calculate subjective value (SV) of the lottery for each trial\n",
    "        svLotto = value * prob\n",
    "        svRef   = 5 ** α[idx]  # Reference value\n",
    "\n",
    "        # Convert SV into a probability of choosing the lottery using the inverse logit function.\n",
    "        p  = (svLotto - svRef) / γ[idx]\n",
    "        mu = pm.invlogit(p)\n",
    "\n",
    "        # Define likelihood of observations using a Binomial distribution, as choice is binary.\n",
    "        choice = pm.Binomial('choice', 1, mu, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "           \n",
    "    return(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e968249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Utility(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    Estimate the utility function of the subjects using a model that accounts for both the value of an outcome \n",
    "    and the probability of its occurrence.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing data on choice, value levels, risk, and ambiguity for each trial.\n",
    "    - n_subs: Number of subjects in the dataset.\n",
    "    - idx: Subject index for each trial (used for modeling individual variations).\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the probabilistic model for utility function\n",
    "    with pm.Model() as Utility:\n",
    "        \n",
    "        # Hyperpriors define group-level distributions for subject-specific parameters.\n",
    "        alpha_a = pm.Normal('alpha_a',  4,   1)  # Shape parameter for risk attitude\n",
    "        alpha_b = pm.Normal('alpha_b', 7,   3)  # Rate parameter for risk attitude\n",
    "        bMu     = pm.Normal('bMu',     .65, 1)  # Group-level mean for ambiguity modulation\n",
    "        bSig    = pm.Gamma('bSig',     4,   1)  # Group-level standard deviation for ambiguity modulation\n",
    "\n",
    "        # Individual subject priors.\n",
    "        alpha = pm.Beta('alpha',  4, 7, shape = n_subs)                        # Subject-specific utility curvature\n",
    "        α = pm.Deterministic('α', alpha * 2)                                               # Double the value of alpha for further computations\n",
    "        β = pm.TruncatedNormal('β',  bMu, bSig, lower = -1.5, upper = 1.5, shape = n_subs) # Ambiguity modulation\n",
    "        γ = pm.LogNormal('γ', 0, .25, shape = n_subs)                                   # Inverse temperature parameter\n",
    "\n",
    "        # Calculate expected value of outcome using a power function.\n",
    "        value = df['value'].values ** α[idx]  # Subjective value based on curvature parameter\n",
    "        prob  = df['risk'].values  - (β[idx] * (df['ambiguity'].values/2))  # Probability of outcome considering ambiguity\n",
    "\n",
    "        # Calculate subjective value (SV) of the lottery for each trial\n",
    "        svLotto = value * prob\n",
    "        svRef   = 5 ** α[idx]  # Reference value\n",
    "\n",
    "        # Convert SV into a probability of choosing the lottery using the inverse logit function.\n",
    "        p  = (svLotto - svRef) / γ[idx]\n",
    "        mu = pm.invlogit(p)\n",
    "\n",
    "        # Define likelihood of observations using a Binomial distribution, as choice is binary.\n",
    "        choice = pm.Binomial('choice', 1, mu, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "           \n",
    "    return(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3204103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Utility_th(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    Estimate the utility function of the subjects using a model that accounts for both the value of an outcome \n",
    "    and the probability of its occurrence, with a modified choice function incorporating tremble hand effect (γ).\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing data on choice, value levels, risk, and ambiguity for each trial.\n",
    "    - n_subs: Number of subjects in the dataset.\n",
    "    - idx: Subject index for each trial (used for modeling individual variations).\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the probabilistic model for the utility function\n",
    "    with pm.Model() as trembel_hand:\n",
    "        \n",
    "        # Hyperpriors: Define group-level distributions for subject-specific parameters.\n",
    "        alpha_a = pm.TruncatedNormal('alpha_a', 4, 1, lower = 1)  # Shape parameter for utility curvature\n",
    "        alpha_b = pm.TruncatedNormal('alpha_b', 7, 1, lower = 1)  # Rate parameter for utility curvature\n",
    "\n",
    "        g_a = pm.TruncatedNormal('g_a', 2, 1, lower = 1)  # Shape parameter for tremble hand effect\n",
    "        g_b = pm.TruncatedNormal('g_b', 2, 1, lower = 1)  # Rate parameter for tremble hand effect\n",
    "\n",
    "        bMu  = pm.Normal('bMu', .65, .5)  # Mean for ambiguity modulation\n",
    "        bSig = pm.Gamma('bSig', 2, 1)     # Standard deviation for ambiguity modulation\n",
    "\n",
    "        # Individual subject priors.\n",
    "        alpha = pm.Beta('alpha', alpha_a, alpha_b, shape = n_subs)  # Subject-specific utility curvature\n",
    "        α = pm.Deterministic('α', alpha * 2)  # Double the value of alpha for further computations\n",
    "        β = pm.TruncatedNormal('β', bMu, bSig, lower = -1.5, upper = 1.5, shape = n_subs)  # Ambiguity modulation\n",
    "        γ = pm.Beta('γ', g_a, g_b, shape = n_subs)  # Tremble hand effect (probability of random choice)\n",
    "\n",
    "        # Calculate expected value of outcome using a power function.\n",
    "        value = df['value'].values ** α[idx]\n",
    "        prob  = df['risk'].values - (β[idx] * (df['ambiguity'].values/2))\n",
    "\n",
    "        svLotto = value * prob\n",
    "        svRef   = 5 ** α[idx]\n",
    "        \n",
    "        # Convert SV into a modified probability of choosing the lottery using the inverse logit function \n",
    "        # and the tremble hand effect.\n",
    "        p = (1/(1+np.exp(-(svLotto - svRef)))) * (1-γ[idx]) + γ[idx] * .5\n",
    "        \n",
    "        # Define likelihood of observations using a Binomial distribution, as choice is binary.\n",
    "        choice = pm.Binomial('choice', 1, p, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "        \n",
    "    return(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee1c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estamte_values_ordinal(df, n_subs, idx):\n",
    "    \"\"\"\n",
    "    Estimate the value of different reward levels using ordinal constraints and a common hyperprior for each level. \n",
    "    The model ensures that the levels are positive (ordinal constraints).\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with trial-specific details, such as choices, value levels, risk, and ambiguity levels.\n",
    "    - n_sub: Total number of subjects in the dataset.\n",
    "    - idx: A list indicating the subject ID for each observation/trial.\n",
    "\n",
    "    Returns:\n",
    "    - trace: Samples from the posterior distribution of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    with pm.Model() as estimate:\n",
    "\n",
    "        # Hyperparameters for group-level distributions\n",
    "        bMu  = pm.Normal('bMu', .65, 1)     # Mean for ambiguity effect distribution\n",
    "        bSig = pm.Gamma('bSig', 2, 1)       # SD for ambiguity effect distribution\n",
    "\n",
    "        # Hyperparameters for group-level subjective value levels\n",
    "        l1Mu = pm.TruncatedNormal('l1Mu', 4, 2, lower=.1)  # Mean for value of level 1\n",
    "        l2Mu = pm.TruncatedNormal('l2Mu', 4, 2, lower=.1)  # ... level 2\n",
    "        l3Mu = pm.TruncatedNormal('l3Mu', 4, 2, lower=.1)  # ... level 3\n",
    "        l4Mu = pm.TruncatedNormal('l4Mu', 4, 2, lower=.1)  # ... level 4\n",
    "        \n",
    "        l1sd = pm.Gamma('l1sd', 3, 1)  # SD for value of level 1\n",
    "        l2sd = pm.Gamma('l2sd', 3, 1)  # ... level 2\n",
    "        l3sd = pm.Gamma('l3sd', 3, 1)  # ... level 3\n",
    "        l4sd = pm.Gamma('l4sd', 3, 1)  # ... level 4\n",
    "        \n",
    "        # Subject-specific priors \n",
    "        β = pm.Normal('β',    bMu, bSig, shape = n_subs)   # Modulation of ambiguity effect\n",
    "        γ = pm.Lognormal('γ', 0, 0.25, shape = n_subs)   # Inverse temperature, impacting choice stochasticity\n",
    "\n",
    "        # Priors for subjective values of the different reward levels for each subject.\n",
    "        level1 = pm.TruncatedNormal('level1', l1Mu, l1sd, lower = 0, shape = n_subs)\n",
    "        level2 = pm.TruncatedNormal('level2', l2Mu, l2sd, lower = 0, shape = n_subs)\n",
    "        level3 = pm.TruncatedNormal('level3', l3Mu, l3sd, lower = 0, shape = n_subs)\n",
    "        level4 = pm.TruncatedNormal('level4', l4Mu, l4sd, lower = 0, shape = n_subs)\n",
    "\n",
    "        # Calculate the total expected value for each trial by combining values from different levels\n",
    "        val = (df['l1'].values * level1[idx] + \n",
    "               df['l2'].values * level2[idx] + \n",
    "               df['l3'].values * level3[idx] + \n",
    "               df['l4'].values * level4[idx]) \n",
    "\n",
    "        # Calculate adjusted probability by considering both risk and ambiguity levels modulated by β\n",
    "        prob = (df['risk'].values) - (β[idx] * (df['ambiguity'].values/2))  \n",
    "\n",
    "        # Compute the subjective value of the lottery option\n",
    "        svLotto = val * prob\n",
    "        svRef   = level1[idx]  # The subjective value of the reference option\n",
    "\n",
    "        # Transform the SV difference between lottery and reference into a choice probability using the logistic function\n",
    "        p  = (svLotto - svRef) / γ[idx]\n",
    "        mu = pm.invlogit(p)\n",
    "\n",
    "        # Likelihood of the observed choices given the computed probabilities\n",
    "        choice = pm.Binomial('choice', 1, mu, observed=df['choice'])\n",
    "\n",
    "        trace = pm.sample(idata_kwargs={'log_likelihood':True})\n",
    "        \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ec2555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gMu, gSig, γ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:46&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 107 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_a, alpha_b, bMu, bSig, alpha, β, γ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:26&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 206 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_a, alpha_b, g_a, g_b, bMu, bSig, alpha, β, γ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:47&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 227 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [bMu, bSig, l1Mu, l2Mu, l3Mu, l4Mu, l1sd, l2sd, l3sd, l4sd, β, γ, level1, level2, level3, level4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 07:51&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 472 seconds.\n"
     ]
    }
   ],
   "source": [
    "mon_simple        = straw_man(             db_mon, n_subs, sub_idx)\n",
    "mon_utility       = Utility(               db_mon, n_subs, sub_idx)\n",
    "mon_trmbling_hand = Utility_th(            db_mon, n_subs, sub_idx)\n",
    "mon_estimated     = estamte_values_ordinal(db_mon, n_subs, sub_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a904288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>estimated</th>\n",
       "      <td>0</td>\n",
       "      <td>-3787.790124</td>\n",
       "      <td>822.589789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.99594</td>\n",
       "      <td>69.197208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classic Utility</th>\n",
       "      <td>1</td>\n",
       "      <td>-5766.437499</td>\n",
       "      <td>257.203259</td>\n",
       "      <td>1978.647375</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>59.340803</td>\n",
       "      <td>48.065272</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trembling-hand</th>\n",
       "      <td>2</td>\n",
       "      <td>-5799.497327</td>\n",
       "      <td>412.703680</td>\n",
       "      <td>2011.707203</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>54.402097</td>\n",
       "      <td>47.089385</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple model</th>\n",
       "      <td>3</td>\n",
       "      <td>-11034.417600</td>\n",
       "      <td>96.198072</td>\n",
       "      <td>7246.627475</td>\n",
       "      <td>0.00406</td>\n",
       "      <td>17.694861</td>\n",
       "      <td>69.424972</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rank      elpd_loo       p_loo    elpd_diff   weight  \\\n",
       "estimated           0  -3787.790124  822.589789     0.000000  0.99594   \n",
       "Classic Utility     1  -5766.437499  257.203259  1978.647375  0.00000   \n",
       "Trembling-hand      2  -5799.497327  412.703680  2011.707203  0.00000   \n",
       "simple model        3 -11034.417600   96.198072  7246.627475  0.00406   \n",
       "\n",
       "                        se        dse  warning scale  \n",
       "estimated        69.197208   0.000000     True   log  \n",
       "Classic Utility  59.340803  48.065272    False   log  \n",
       "Trembling-hand   54.402097  47.089385     True   log  \n",
       "simple model     17.694861  69.424972     True   log  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_dict = {'simple model':       mon_simple, \n",
    "                'Classic Utility':    mon_utility,\n",
    "                'Trembling-hand':     mon_trmbling_hand, \n",
    "                'estimated':          mon_estimated,\n",
    "\n",
    "}\n",
    "\n",
    "comp = az.compare(compare_dict)\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f977c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [gMu, gSig, γ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:08&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 69 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [bMu, bSig, l1Mu, l2Mu, l3Mu, l4Mu, l1sd, l2sd, l3sd, l4sd, β, γ, level1, level2, level3, level4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 08:15&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 496 seconds.\n"
     ]
    }
   ],
   "source": [
    "med_simple    = straw_man(             db_med, n_subs_med, sub_idx_med)\n",
    "med_estimated = estamte_values_ordinal(db_med, n_subs_med, sub_idx_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7ea1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Estimated</th>\n",
       "      <td>0</td>\n",
       "      <td>-4098.374285</td>\n",
       "      <td>783.275078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990839</td>\n",
       "      <td>72.509407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple model</th>\n",
       "      <td>1</td>\n",
       "      <td>-9514.905542</td>\n",
       "      <td>181.550509</td>\n",
       "      <td>5416.531257</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>44.849519</td>\n",
       "      <td>73.563528</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank     elpd_loo       p_loo    elpd_diff    weight         se  \\\n",
       "Estimated        0 -4098.374285  783.275078     0.000000  0.990839  72.509407   \n",
       "Simple model     1 -9514.905542  181.550509  5416.531257  0.009161  44.849519   \n",
       "\n",
       "                    dse  warning scale  \n",
       "Estimated      0.000000     True   log  \n",
       "Simple model  73.563528     True   log  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_dict = {'Simple model': med_simple, \n",
    "                'Estimated':      med_estimated\n",
    "}\n",
    "\n",
    "comp = az.compare(compare_dict)\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe7b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1: mean: 10.942753012048193 SD:  2.7310843373493974\n",
      "level 2: mean: 4.143421686746988 SD:  1.8455060240963859\n",
      "level 3: mean: 5.045620481927711 SD:  2.3550993975903616\n",
      "level 4: mean: 3.9387138554216863 SD:  2.1763162650602412\n"
     ]
    }
   ],
   "source": [
    "print(\"level 1: mean:\", az.summary(mon_estimated, var_names=['level1'])['mean'].mean(), \"SD: \", az.summary(mon_estimated, var_names=['level1'])['sd'].mean())\n",
    "print(\"level 2: mean:\", az.summary(mon_estimated, var_names=['level2'])['mean'].mean(), \"SD: \", az.summary(mon_estimated, var_names=['level2'])['sd'].mean())\n",
    "print(\"level 3: mean:\", az.summary(mon_estimated, var_names=['level3'])['mean'].mean(), \"SD: \", az.summary(mon_estimated, var_names=['level3'])['sd'].mean())\n",
    "print(\"level 4: mean:\", az.summary(mon_estimated, var_names=['level4'])['mean'].mean(), \"SD: \", az.summary(mon_estimated, var_names=['level4'])['sd'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93eb6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1: mean: 8.632475903614457 SD:  2.5304156626506025\n",
      "level 2: mean: 12.634256024096386 SD:  4.233024096385543\n",
      "level 3: mean: 4.6652048192771085 SD:  2.5595090361445787\n",
      "level 4: mean: 2.3761626506024096 SD:  1.601240963855422\n"
     ]
    }
   ],
   "source": [
    "print(\"level 1: mean:\", az.summary(med_estimated, var_names=['level1'])['mean'].mean(), \"SD: \", az.summary(med_estimated, var_names=['level1'])['sd'].mean())\n",
    "print(\"level 2: mean:\", az.summary(med_estimated, var_names=['level2'])['mean'].mean(), \"SD: \", az.summary(med_estimated, var_names=['level2'])['sd'].mean())\n",
    "print(\"level 3: mean:\", az.summary(med_estimated, var_names=['level3'])['mean'].mean(), \"SD: \", az.summary(med_estimated, var_names=['level3'])['sd'].mean())\n",
    "print(\"level 4: mean:\", az.summary(med_estimated, var_names=['level4'])['mean'].mean(), \"SD: \", az.summary(med_estimated, var_names=['level4'])['sd'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a947cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar process for the monetery dataset\n",
    "df = db_mon[['sub','age', 'gender']].sort_values('sub').drop_duplicates().reset_index(drop=True)\n",
    "df['age'] = df.age.astype('int')\n",
    "\n",
    "# extract parameters from the model\n",
    "level1 = az.summary(mon_estimated, var_names=['level1'])[['mean']]\n",
    "level2 = az.summary(mon_estimated, var_names=['level2'])[['mean']]\n",
    "level3 = az.summary(mon_estimated, var_names=['level3'])[['mean']]\n",
    "level4 = az.summary(mon_estimated, var_names=['level4'])[['mean']]\n",
    "beta   = az.summary(mon_estimated, var_names=['β']     )[['mean']]\n",
    "\n",
    "# change column names\n",
    "level1 = level1.rename(columns={'mean': \"level1_mon\"}).reset_index(drop=True)\n",
    "level2 = level2.rename(columns={'mean': \"level2_mon\"}).reset_index(drop=True)\n",
    "level3 = level3.rename(columns={'mean': \"level3_mon\"}).reset_index(drop=True)\n",
    "level4 = level4.rename(columns={'mean': \"level4_mon\"}).reset_index(drop=True)\n",
    "beta   = beta.rename(  columns={'mean': \"amb_est_mon\"}  ).reset_index(drop=True)\n",
    "\n",
    "# combine to a single dataframe\n",
    "df = df.merge(level1, left_index=True, right_index=True)\n",
    "df = df.merge(level2, left_index=True, right_index=True)\n",
    "df = df.merge(level3, left_index=True, right_index=True)\n",
    "df = df.merge(level4, left_index=True, right_index=True)\n",
    "df = df.merge(beta,   left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters from the model\n",
    "level1 = az.summary(med_estimated, var_names=['level1'])[['mean']]\n",
    "level2 = az.summary(med_estimated, var_names=['level2'])[['mean']]\n",
    "level3 = az.summary(med_estimated, var_names=['level3'])[['mean']]\n",
    "level4 = az.summary(med_estimated, var_names=['level4'])[['mean']]\n",
    "beta   = az.summary(med_estimated, var_names=['β']     )[['mean']]\n",
    "\n",
    "# change column names\n",
    "level1 = level1.rename(columns={'mean': \"level1_med\"}).reset_index(drop=True)\n",
    "level2 = level2.rename(columns={'mean': \"level2_med\"}).reset_index(drop=True)\n",
    "level3 = level3.rename(columns={'mean': \"level3_med\"}).reset_index(drop=True)\n",
    "level4 = level4.rename(columns={'mean': \"level4_med\"}).reset_index(drop=True)\n",
    "beta   = beta.rename(  columns={'mean': \"amb_est_med\"}  ).reset_index(drop=True)\n",
    "\n",
    "# combine to a single dataframe\n",
    "df = df.merge(level1, left_index=True, right_index=True)\n",
    "df = df.merge(level2, left_index=True, right_index=True)\n",
    "df = df.merge(level3, left_index=True, right_index=True)\n",
    "df = df.merge(level4, left_index=True, right_index=True)\n",
    "df = df.merge(beta,   left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0309d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters from the model\n",
    "alpha = az.summary(mon_utility, var_names=['α'])[['mean']]\n",
    "beta  = az.summary(mon_utility, var_names=['β'])[['mean']]\n",
    "\n",
    "# change column names\n",
    "alpha = alpha.rename(columns={'mean': \"risk_ave\"}).reset_index(drop=True)\n",
    "beta  = beta.rename( columns={'mean': \"amb_ave\"} ).reset_index(drop=True)\n",
    "\n",
    "# combine to a single dataframe\n",
    "df = df.merge(alpha, left_index=True, right_index=True)\n",
    "df = df.merge(beta, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30518256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x, y):\n",
    "    with pm.Model() as RR:\n",
    "\n",
    "        a = pm.Normal('intercept', 0, 1)\n",
    "        b = pm.Normal('slope', 0, 1)\n",
    "        eps = pm.Exponential('eps', 1)\n",
    "        y_hat = a + b*x\n",
    "\n",
    "        nu = pm.InverseGamma(\"nu\", alpha=3, beta=1)\n",
    "\n",
    "        likelihood = pm.StudentT(\"likelihood\", mu=y_hat, sigma=eps, nu=nu, observed=y)\n",
    "\n",
    "        trace_robust = pm.sample()\n",
    "        \n",
    "    return(trace_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = corr(df.amb_est_mon, df.amb_est_med)\n",
    "age_med = corr(df.age, df.amb_est_med)\n",
    "age_mon = corr(df.age, df.amb_est_mon)\n",
    "\n",
    "es = az.summary(est, var_names=['slope','intercept'], hdi_prob=.89)[['mean','hdi_5.5%','hdi_94.5%']]\n",
    "agemed = az.summary(age_med, var_names=['slope','intercept'], hdi_prob=.89)[['mean','hdi_5.5%','hdi_94.5%']]\n",
    "agemon = az.summary(age_mon, var_names=['slope','intercept'], hdi_prob=.89)[['mean','hdi_5.5%','hdi_94.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the dataframe 'df' from wide to long format using the melt function.\n",
    "\n",
    "# calculate the SV of each level\n",
    "df['level1m'] = df['level1_mon']\n",
    "df['level2m'] = df['level1m'] + df['level2_mon']\n",
    "df['level3m'] = df['level2m'] + df['level3_mon']\n",
    "df['level4m'] = df['level3m'] + df['level4_mon']\n",
    "\n",
    "df_long_mon = df.melt(id_vars='sub',\n",
    "                      value_vars=['level1m', 'level2m', 'level3m', 'level4m'], \n",
    "                      var_name='level')\n",
    "\n",
    "\n",
    "level_mapping = {\n",
    "    'level1m': 5,\n",
    "    'level2m': 8,\n",
    "    'level3m': 12,\n",
    "    'level4m': 25\n",
    "}\n",
    "\n",
    "\n",
    "# Apply the mapping to the 'level' column in 'df_long_med' and create a new column 'levelName' that holds the descriptive names.\n",
    "df_long_mon['levelName'] = df_long_mon['level'].map(level_mapping)\n",
    "\n",
    "df['level1md'] = df['level1_med']\n",
    "df['level2md'] = df['level1md'] + df['level2_med']\n",
    "df['level3md'] = df['level2md'] + df['level3_med']\n",
    "df['level4md'] = df['level3md'] + df['level4_med']\n",
    "\n",
    "# Reshape the dataframe 'df' from wide to long format using the melt function.\n",
    "df_long_med = df.melt(id_vars='sub',\n",
    "                      value_vars=['level1md', 'level2md', 'level3md', 'level4md'], \n",
    "                      var_name='level')\n",
    "\n",
    "\n",
    "# Create a mapping dictionary for levels. This provides a more descriptive name for each 'level' in 'df_long_med'.\n",
    "level_mapping = {\n",
    "    'level1md': 'Slight',\n",
    "    'level2md': 'Moderate',\n",
    "    'level3md': 'Major',\n",
    "    'level4md': 'Complete recovery'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'level' column in 'df_long_med' and create a new column 'levelName' that holds the descriptive names.\n",
    "df_long_med['levelName'] = df_long_med['level'].map(level_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edba54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will visualize the relationship between different levels and their estimated values for Monetary and Medical contexts.\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8)) # Initialize a 1x2 subplot layout, with a shared y-axis.\n",
    "\n",
    "\n",
    "# Plot the estimated value for each level in the 'Monetary' context on the first axis.\n",
    "sns.lineplot(data=df_long_mon, x='levelName', y='value', ax=axes[0])\n",
    "\n",
    "# Plot the estimated value for each level in the 'Medical' context on the second axis.\n",
    "sns.lineplot(data=df_long_med, x='levelName', y='value', ax=axes[1])\n",
    "\n",
    "# Set the title for each subplot.\n",
    "axes[0].set_title('Monetary', fontweight=\"bold\", size=30)\n",
    "axes[1].set_title('Medical', fontweight=\"bold\", size=30)\n",
    "\n",
    "# Set the y-axis label for the first subplot.\n",
    "axes[0].set_ylabel('Estimated Value', fontsize=24.0)\n",
    "axes[1].set_ylabel('', fontsize=24.0)\n",
    "\n",
    "\n",
    "# Remove x-axis labels as they are self-explanatory with the data points.\n",
    "axes[0].set_xlabel('', fontsize=24.0)\n",
    "axes[1].set_xlabel('', fontsize=24.0)\n",
    "\n",
    "# Adjust the tick parameters to increase font size, ensuring better readability.\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "# Add a slight rotation to the x-axis tick labels on the second plot for better visualization.\n",
    "axes[1].tick_params(axis='x', labelrotation=8)\n",
    "\n",
    "# Set the background color for both plots to white for clarity and aesthetic appeal.\n",
    "axes[0].set_facecolor('White')\n",
    "axes[1].set_facecolor('White')\n",
    "\n",
    "# Remove the right and top spines from both plots to reduce visual clutter.\n",
    "for spine in ['right', 'top']:\n",
    "    axes[0].spines[spine].set_color('white')\n",
    "    axes[1].spines[spine].set_color('white')\n",
    "\n",
    "subplot_labels = ['A', 'B']\n",
    "\n",
    "for ax, label in zip(axes.flat, subplot_labels):\n",
    "    # Position the text at the top left of each subplot\n",
    "    # Adjust x and y values to change the position of the label\n",
    "    ax.text(-0.1, 1.1, label, transform=ax.transAxes, fontsize=36, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "# Adjust the layout to ensure that the plots do not overlap and everything fits well.\n",
    "#fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae049e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_loo = az.compare({\"hierarchical\": med_estimated, \"pooled\": mon_estimated})\n",
    "df_comp_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9542aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_loo = az.loo(med_estimated)\n",
    "\n",
    "hierarchical_loo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e2348",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_loo = az.loo(mon_estimated)\n",
    "\n",
    "hierarchical_loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b99586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will visualize the relationship between different levels and their estimated values for Monetary and Medical contexts.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(26, 8)) # Initialize a 1x2 subplot layout, with a shared y-axis.\n",
    "\n",
    "sns.scatterplot(data = df, x = 'amb_est_mon', y = 'amb_est_med', s = 200, ax=axes[0])\n",
    "sns.lineplot(x = df.amb_est_mon, \n",
    "             y = es['mean']['intercept']+es['mean']['slope']*df.amb_est_mon, \n",
    "             ax=axes[0])\n",
    "\n",
    "sns.scatterplot(data = df, x = 'age', y = 'amb_est_mon', s = 200, ax=axes[1])\n",
    "sns.lineplot(x = df.age, \n",
    "             y = agemon['mean']['intercept']+agemon['mean']['slope']*df.age, \n",
    "             ax=axes[1])\n",
    "\n",
    "sns.scatterplot(data = df, x = 'age', y = 'amb_est_med', s = 200, ax=axes[2])\n",
    "sns.lineplot(x = df.age, \n",
    "             y = agemed['mean']['intercept']+agemed['mean']['slope']*df.age, \n",
    "             ax=axes[2])\n",
    "\n",
    "\n",
    "# Set the title for each subplot.\n",
    "axes[0].set_title('Ambiguity aversion', fontweight=\"bold\", size=30)\n",
    "axes[1].set_title('Monetary', fontweight=\"bold\", size=30)\n",
    "axes[2].set_title('Medical', fontweight=\"bold\", size=30)\n",
    "\n",
    "# Set the y-axis label for the first subplot.\n",
    "axes[0].set_ylabel('β Medical', fontsize=24.0)\n",
    "axes[1].set_ylabel('Ambiguity aversion (β)', fontsize=24.0)\n",
    "axes[2].set_ylabel('', fontsize=24.0)\n",
    "\n",
    "\n",
    "# Remove x-axis labels as they are self-explanatory with the data points.\n",
    "axes[0].set_xlabel('β Monetary', fontsize=24.0)\n",
    "axes[1].set_xlabel('Age', fontsize=24.0)\n",
    "axes[2].set_xlabel('Age', fontsize=24.0)\n",
    "\n",
    "# Adjust the tick parameters to increase font size, ensuring better readability.\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "\n",
    "text = 'β = {:.3f},\\n89% HDPi [{:.3f}, {:.3f}]'.format(float(es['mean']['slope']),\n",
    "                                                       float(es['hdi_5.5%']['slope']),\n",
    "                                                       float(es['hdi_94.5%']['slope']))\n",
    "axes[0].text(-.4, 1.2, text, fontsize=20)\n",
    "\n",
    "\n",
    "text = 'β = {:.3f},\\n89% HDPi [{:.3f}, {:.3f}]'.format(float(agemon['mean']['slope']),\n",
    "                                                       float(agemon['hdi_5.5%']['slope']),\n",
    "                                                       float(agemon['hdi_94.5%']['slope']))\n",
    "axes[1].text(20, 1.25, text, fontsize=20)\n",
    "\n",
    "text = 'β = {:.3f},\\n89% HDPi [{:.3f}, {:.3f}]'.format(float(agemed['mean']['slope']),\n",
    "                                                       float(agemed['hdi_5.5%']['slope']),\n",
    "                                                       float(agemed['hdi_94.5%']['slope']))\n",
    "axes[2].text(20, 1.25, text, fontsize=20)\n",
    "\n",
    "# Set the background color for both plots to white for clarity and aesthetic appeal.\n",
    "axes[0].set_facecolor('White')\n",
    "axes[1].set_facecolor('White')\n",
    "axes[2].set_facecolor('White')\n",
    "\n",
    "# Remove the right and top spines from both plots to reduce visual clutter.\n",
    "for spine in ['right', 'top']:\n",
    "    axes[0].spines[spine].set_color('white')\n",
    "    axes[1].spines[spine].set_color('white')\n",
    "    axes[2].spines[spine].set_color('white')\n",
    "    \n",
    "    \n",
    "subplot_labels = ['A', 'B', 'C']\n",
    "\n",
    "for ax, label in zip(axes.flat, subplot_labels):\n",
    "    # Position the text at the top left of each subplot\n",
    "    # Adjust x and y values to change the position of the label\n",
    "    ax.text(-0.1, 1.1, label, transform=ax.transAxes, fontsize=36, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "\n",
    "# Adjust the layout to ensure that the plots do not overlap and everything fits well.\n",
    "#fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
