{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8c4f6",
   "metadata": {},
   "source": [
    "# Modeling Reversal Task\n",
    "\n",
    "### RW model of the reversal task in the aging experiment\n",
    "\n",
    "The aim of this notbook is to see if age affects appetative reversal learning.\n",
    "\n",
    "participants have 70 trials 40% reinforced.\n",
    "\n",
    "reversal of stimuli occurs after 35 trials.\n",
    "\n",
    "This notbook is based on Or's simulation of SCR.\n",
    "\n",
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "809a0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c7023",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "make sure only participant with complete data set are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e15d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/Data/Lab_Projects/Aging/behavioral/Reversal/AG_60_RV/ETLearning_1638474572_60.csv\n",
      "error\n",
      "number of subject:  48\n"
     ]
    }
   ],
   "source": [
    "glober = '/media/Data/Lab_Projects/Aging/behavioral/Reversal/AG_*_RV/ETLearning_*.csv'\n",
    "\n",
    "db = pd.DataFrame()\n",
    "\n",
    "for sub in glob(glober):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(sub)\n",
    "        df['sub'] = sub.split('_')[2]\n",
    "        if df.shape[0] == 70:\n",
    "            \n",
    "            db = db.append(df[df.trialNum<36])\n",
    "    except:\n",
    "        print(sub)\n",
    "        print('error')\n",
    "\n",
    "print('number of subject: ', len(db['sub'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f026fe",
   "metadata": {},
   "source": [
    "## get descriptive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d26b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subj   = len(db['sub'].unique())\n",
    "n_trials = max(db.trialNum)\n",
    "\n",
    "trials, subj = np.meshgrid(range(n_trials), range(n_subj))\n",
    "trials = tt.as_tensor_variable(trials.T)\n",
    "subj   = tt.as_tensor_variable(subj.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de89482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim   = np.reshape([db['rectOri']],   (n_subj, n_trials)).T\n",
    "reward = np.reshape([db['rectValue']], (n_subj, n_trials)).T\n",
    "rating = np.reshape([db['rating']],    (n_subj, n_trials)).T\n",
    "\n",
    "stim   = np.array(stim/45,  dtype='int')\n",
    "reward = np.array(reward/6*9, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b3681db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = tt.as_tensor_variable(stim)\n",
    "reward = tt.as_tensor_variable(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e65d1b",
   "metadata": {},
   "source": [
    "# create a pymc3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "457ca1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# generate functions to run\n",
    "def update_Q(stim, reward,\n",
    "             Qs,vec,\n",
    "             alpha, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by theano.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the theano.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: tt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "     \n",
    "    PE = reward - Qs[tt.arange(n_subj), stim]\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * PE)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5319763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:08<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 190 seconds.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as mB:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "057f4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.053</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2708.0</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2539.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3618.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2517.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2878.0</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3264.0</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.118</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3463.0</td>\n",
       "      <td>2561.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2938.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2872.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2699.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2548.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2643.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>2093.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.019</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2368.0</td>\n",
       "      <td>1622.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2522.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.053  0.029   0.001    0.102      0.001    0.000    2228.0   \n",
       "alpha[1]   0.039  0.018   0.004    0.071      0.000    0.000    2708.0   \n",
       "alpha[2]   0.027  0.016   0.000    0.055      0.000    0.000    2539.0   \n",
       "alpha[3]   0.079  0.029   0.026    0.133      0.000    0.000    3618.0   \n",
       "alpha[4]   0.022  0.016   0.000    0.051      0.000    0.000    2517.0   \n",
       "alpha[5]   0.038  0.028   0.000    0.088      0.000    0.000    2878.0   \n",
       "alpha[6]   0.013  0.011   0.000    0.034      0.000    0.000    3264.0   \n",
       "alpha[7]   0.118  0.040   0.042    0.192      0.001    0.000    3463.0   \n",
       "alpha[8]   0.052  0.034   0.000    0.111      0.001    0.000    2600.0   \n",
       "alpha[9]   0.027  0.020   0.000    0.062      0.000    0.000    3233.0   \n",
       "alpha[10]  0.040  0.022   0.000    0.077      0.000    0.000    1983.0   \n",
       "alpha[11]  0.166  0.051   0.073    0.265      0.001    0.001    2938.0   \n",
       "alpha[12]  0.048  0.025   0.000    0.089      0.000    0.000    2872.0   \n",
       "alpha[13]  0.016  0.012   0.000    0.038      0.000    0.000    2699.0   \n",
       "alpha[14]  0.151  0.060   0.039    0.262      0.001    0.001    2548.0   \n",
       "alpha[15]  0.028  0.021   0.000    0.067      0.000    0.000    2643.0   \n",
       "alpha[16]  0.013  0.011   0.000    0.032      0.000    0.000    3238.0   \n",
       "alpha[17]  0.062  0.029   0.008    0.112      0.001    0.000    2144.0   \n",
       "alpha[18]  0.019  0.017   0.000    0.049      0.000    0.000    2368.0   \n",
       "alpha[19]  0.031  0.021   0.000    0.069      0.000    0.000    2522.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     1069.0    1.0  \n",
       "alpha[1]     1823.0    1.0  \n",
       "alpha[2]     1715.0    1.0  \n",
       "alpha[3]     2237.0    1.0  \n",
       "alpha[4]     1382.0    1.0  \n",
       "alpha[5]     1887.0    1.0  \n",
       "alpha[6]     1876.0    1.0  \n",
       "alpha[7]     2561.0    1.0  \n",
       "alpha[8]     1454.0    1.0  \n",
       "alpha[9]     1987.0    1.0  \n",
       "alpha[10]    1063.0    1.0  \n",
       "alpha[11]    1874.0    1.0  \n",
       "alpha[12]    1064.0    1.0  \n",
       "alpha[13]    1594.0    1.0  \n",
       "alpha[14]    1502.0    1.0  \n",
       "alpha[15]    2020.0    1.0  \n",
       "alpha[16]    2093.0    1.0  \n",
       "alpha[17]    1286.0    1.0  \n",
       "alpha[18]    1622.0    1.0  \n",
       "alpha[19]    1817.0    1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2eb238a8-005f-422d-bbca-54d7a147bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 185 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_I:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_I = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65f6865f-eff2-4d9b-8104-11f00f9d4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.587</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>2475.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4774.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.143</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.244</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4145.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.108</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3915.0</td>\n",
       "      <td>2231.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.485</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3476.0</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.335</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3453.0</td>\n",
       "      <td>3093.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3174.0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.491</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>7974.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4207.0</td>\n",
       "      <td>2582.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3078.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3061.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.264</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3412.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4321.0</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.421</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4153.0</td>\n",
       "      <td>2899.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.433</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3389.0</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1758.0</td>\n",
       "      <td>2871.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.275</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4106.0</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.511</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.071</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5544.0</td>\n",
       "      <td>2167.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.327</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>2757.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.587  0.262   0.127    0.999      0.004    0.003    5281.0   \n",
       "alpha[1]   0.108  0.083   0.000    0.225      0.002    0.002    4774.0   \n",
       "alpha[2]   0.143  0.098   0.001    0.317      0.001    0.001    3693.0   \n",
       "alpha[3]   0.244  0.098   0.077    0.432      0.001    0.001    4145.0   \n",
       "alpha[4]   0.108  0.083   0.000    0.259      0.001    0.001    3915.0   \n",
       "alpha[5]   0.485  0.226   0.068    0.907      0.004    0.003    3476.0   \n",
       "alpha[6]   0.335  0.285   0.000    0.846      0.005    0.004    3453.0   \n",
       "alpha[7]   0.400  0.140   0.139    0.654      0.003    0.002    3174.0   \n",
       "alpha[8]   0.491  0.284   0.035    0.968      0.003    0.003    7974.0   \n",
       "alpha[9]   0.447  0.283   0.004    0.911      0.004    0.003    4207.0   \n",
       "alpha[10]  0.269  0.220   0.001    0.743      0.005    0.004    3078.0   \n",
       "alpha[11]  0.462  0.200   0.113    0.867      0.004    0.003    3061.0   \n",
       "alpha[12]  0.264  0.155   0.003    0.530      0.003    0.002    3412.0   \n",
       "alpha[13]  0.050  0.041   0.000    0.120      0.001    0.000    4321.0   \n",
       "alpha[14]  0.421  0.291   0.000    0.907      0.005    0.003    4153.0   \n",
       "alpha[15]  0.433  0.220   0.044    0.843      0.004    0.003    3389.0   \n",
       "alpha[16]  0.361  0.315   0.000    0.907      0.008    0.005    1758.0   \n",
       "alpha[17]  0.275  0.135   0.047    0.530      0.002    0.002    4106.0   \n",
       "alpha[18]  0.511  0.283   0.071    1.000      0.004    0.003    5544.0   \n",
       "alpha[19]  0.327  0.258   0.000    0.843      0.004    0.003    4002.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     2475.0    1.0  \n",
       "alpha[1]     2296.0    1.0  \n",
       "alpha[2]     2026.0    1.0  \n",
       "alpha[3]     1746.0    1.0  \n",
       "alpha[4]     2231.0    1.0  \n",
       "alpha[5]     2312.0    1.0  \n",
       "alpha[6]     3093.0    1.0  \n",
       "alpha[7]     1862.0    1.0  \n",
       "alpha[8]     1964.0    1.0  \n",
       "alpha[9]     2582.0    1.0  \n",
       "alpha[10]    2238.0    1.0  \n",
       "alpha[11]    1664.0    1.0  \n",
       "alpha[12]    1978.0    1.0  \n",
       "alpha[13]    2222.0    1.0  \n",
       "alpha[14]    2899.0    1.0  \n",
       "alpha[15]    1783.0    1.0  \n",
       "alpha[16]    2871.0    1.0  \n",
       "alpha[17]    2222.0    1.0  \n",
       "alpha[18]    2167.0    1.0  \n",
       "alpha[19]    2757.0    1.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_I, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "125ae433-0091-4b97-ba95-b489803d1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/arviz/stats/stats.py:695: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>-4003.300486</td>\n",
       "      <td>79.241475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.87918</td>\n",
       "      <td>25.815531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>-4044.117654</td>\n",
       "      <td>74.104098</td>\n",
       "      <td>40.817168</td>\n",
       "      <td>0.12082</td>\n",
       "      <td>23.204206</td>\n",
       "      <td>10.384456</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo      p_loo      d_loo   weight         se  \\\n",
       "model1     0 -4003.300486  79.241475   0.000000  0.87918  25.815531   \n",
       "model2     1 -4044.117654  74.104098  40.817168  0.12082  23.204206   \n",
       "\n",
       "              dse  warning loo_scale  \n",
       "model1   0.000000     True       log  \n",
       "model2  10.384456    False       log  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05bbfd10-7229-4a13-b3a6-473e50cee83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 15:50<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 953 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_Is:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_Is = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4143cb4-6339-4b21-955b-f11e20689065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2101.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.139</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>2270.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.274</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.164</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.289</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2272.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.399</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.334</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.274</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3283.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.292</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.388</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2698.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>2581.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2647.0</td>\n",
       "      <td>2171.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>2328.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.210</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3558.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.515</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.408</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.309</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.346  0.323   0.000    0.904      0.007    0.005    2101.0   \n",
       "alpha[1]   0.139  0.208   0.000    0.623      0.004    0.003    2991.0   \n",
       "alpha[2]   0.274  0.241   0.000    0.757      0.004    0.003    2035.0   \n",
       "alpha[3]   0.164  0.124   0.010    0.374      0.002    0.002    3326.0   \n",
       "alpha[4]   0.289  0.263   0.000    0.811      0.004    0.003    2272.0   \n",
       "alpha[5]   0.399  0.239   0.000    0.819      0.005    0.003    2047.0   \n",
       "alpha[6]   0.334  0.278   0.000    0.861      0.006    0.004    1341.0   \n",
       "alpha[7]   0.274  0.144   0.032    0.527      0.002    0.002    3283.0   \n",
       "alpha[8]   0.292  0.281   0.000    0.847      0.005    0.003    2323.0   \n",
       "alpha[9]   0.388  0.295   0.000    0.896      0.007    0.005    1193.0   \n",
       "alpha[10]  0.236  0.262   0.000    0.793      0.004    0.003    2698.0   \n",
       "alpha[11]  0.201  0.101   0.038    0.382      0.001    0.001    4257.0   \n",
       "alpha[12]  0.238  0.216   0.000    0.672      0.004    0.003    2647.0   \n",
       "alpha[13]  0.311  0.284   0.000    0.849      0.006    0.004    1550.0   \n",
       "alpha[14]  0.210  0.150   0.006    0.459      0.002    0.002    3558.0   \n",
       "alpha[15]  0.515  0.263   0.002    0.919      0.006    0.004    2114.0   \n",
       "alpha[16]  0.408  0.217   0.001    0.809      0.004    0.003    2380.0   \n",
       "alpha[17]  0.250  0.203   0.001    0.632      0.004    0.003    2491.0   \n",
       "alpha[18]  0.401  0.309   0.000    0.917      0.007    0.005    1373.0   \n",
       "alpha[19]  0.309  0.291   0.000    0.866      0.005    0.004    2238.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     1927.0   1.00  \n",
       "alpha[1]     2270.0   1.00  \n",
       "alpha[2]     1643.0   1.00  \n",
       "alpha[3]     2118.0   1.00  \n",
       "alpha[4]     2127.0   1.00  \n",
       "alpha[5]     1249.0   1.01  \n",
       "alpha[6]      892.0   1.00  \n",
       "alpha[7]     1495.0   1.00  \n",
       "alpha[8]     2188.0   1.00  \n",
       "alpha[9]     1134.0   1.00  \n",
       "alpha[10]    2261.0   1.00  \n",
       "alpha[11]    2581.0   1.00  \n",
       "alpha[12]    2171.0   1.00  \n",
       "alpha[13]    2328.0   1.00  \n",
       "alpha[14]    2109.0   1.00  \n",
       "alpha[15]     862.0   1.00  \n",
       "alpha[16]    1098.0   1.00  \n",
       "alpha[17]    1986.0   1.00  \n",
       "alpha[18]    1255.0   1.00  \n",
       "alpha[19]    2120.0   1.00  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_Is, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44a2e330-0b72-4599-8578-e228d3dfa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/or/miniconda3/envs/neuroAnalysis/lib/python3.7/site-packages/arviz/stats/stats.py:695: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  \"Estimated shape parameter of Pareto distribution is greater than 0.7 for \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0</td>\n",
       "      <td>-4000.762514</td>\n",
       "      <td>104.953049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570773</td>\n",
       "      <td>25.550799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4003.300486</td>\n",
       "      <td>79.241475</td>\n",
       "      <td>2.537972</td>\n",
       "      <td>0.429227</td>\n",
       "      <td>25.815531</td>\n",
       "      <td>6.872247</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>2</td>\n",
       "      <td>-4044.117654</td>\n",
       "      <td>74.104098</td>\n",
       "      <td>43.355140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.204206</td>\n",
       "      <td>8.927458</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo       p_loo      d_loo    weight         se  \\\n",
       "model3     0 -4000.762514  104.953049   0.000000  0.570773  25.550799   \n",
       "model1     1 -4003.300486   79.241475   2.537972  0.429227  25.815531   \n",
       "model2     2 -4044.117654   74.104098  43.355140  0.000000  23.204206   \n",
       "\n",
       "             dse  warning loo_scale  \n",
       "model3  0.000000    False       log  \n",
       "model1  6.872247     True       log  \n",
       "model2  8.927458    False       log  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I, 'model3':trB_Is})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddbe8f",
   "metadata": {},
   "source": [
    "## hierarchal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd609241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 8 jobs)\n",
      "NUTS: [eps, beta, beta_sd, beta_h, alpha, kappa_log, phi, intercept_matt, sd, mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='985' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.31% [985/8000 03:00<21:28 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as m_H:\n",
    "    \n",
    "    # intercept\n",
    "    mu = pm.Normal('mu', 0, 1)\n",
    "    sd = pm.HalfNormal('sd',5) \n",
    "    intercept_matt = pm.Normal('intercept_matt', mu=0, sd=1, shape=n_subj)\n",
    "    intercept = pm.Deterministic('intercept',intercept_matt + mu*sd)\n",
    "    \n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0)\n",
    "\n",
    "    kappa_log = pm.Exponential(\"kappa_log\", lam=1.5)\n",
    "    kappa = pm.Deterministic(\"kappa\", tt.exp(kappa_log))\n",
    "\n",
    "    alpha = pm.Beta(\"alpha\", alpha=phi * kappa, beta=(1.0 - phi) * kappa, shape=n_subj)\n",
    "    \n",
    "    \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 1)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "       \n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec0 = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec0],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "     \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_hB = pm.sample(target_accept=.9, chains=4, cores=8, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(tr_hB, var_names='alpha')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b224f3",
   "metadata": {},
   "source": [
    "## model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = az.compare({'model1':trB, 'model2': tr_hB}, ic='loo')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b706a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a52b65",
   "metadata": {},
   "source": [
    "## Correlate expected value and subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44411662",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trB.posterior.stack(draws=('chain','draw'))\n",
    "a = a.expected_value\n",
    "mean_a = np.mean(a, axis=2)\n",
    "mean_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(10):\n",
    "    cor1 = scipy.stats.pearsonr(rating[:,i], mean_a[:,i])\n",
    "    print(cor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc336ba9",
   "metadata": {},
   "source": [
    "## The Pearce-Hall Hybrid model\n",
    "\n",
    "This is Or's attempt to build the PH Hybrid model. This model doesn't assume a simple constant learning rate (as the RW), rather, it incorporated both a constant learning rate and a dynamic one. The dynamic one is being updated by the amount of new information given. The model goes like that: \n",
    "\n",
    "(1) Vi(k+1) = Vi (k) + (k) + (k)\n",
    "\n",
    "(2)  = shock - Vi(k) \n",
    "\n",
    "(3) (k+1) = || + (1-)(k)\n",
    "\n",
    "So the current value is an update of the previous one plus a constant learning rate (kappa) and an associability weight (alpha) (times the delta = prediction error).\n",
    "\n",
    "The  is set by a constant weight of associability (eta) and the previous .\n",
    "\n",
    "So now, our updating function will include those elements as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b7fde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate functions to run\n",
    "def update_Q_hb(stim, shock,\n",
    "             Qs,vec,alpha,assoc,\n",
    "             eta,kappa, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to Hybrid PH model\n",
    "    For information, please see this paper: https://www.sciencedirect.com/science/article/pii/S0896627316305840?via%3Dihub\n",
    "  \n",
    "    \"\"\"\n",
    "      \n",
    "    delta = shock - Qs[tt.arange(n_subj), stim]\n",
    "    alpha = tt.set_subtensor(alpha[tt.arange(n_subj), stim], eta * abs(delta) + (1-eta)*alpha[tt.arange(n_subj), stim])\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + kappa*alpha[tt.arange(n_subj), stim] * delta)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    # we use the same idea to get the associability per trial\n",
    "    assoc = tt.set_subtensor(assoc[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                alpha[tt.arange(n_subj),1], alpha[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec, alpha, assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae9b4457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, , k_log2, beta, beta_sd, beta_h, kappa, k_log1, phi]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 13:05<00:00 Sampling 4 chains, 459 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/step_methods/hmc/integration.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  energy = kinetic - logp\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 787 seconds.\n",
      "There were 148 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 92 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 124 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 95 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "  \n",
    "    # hyperpriors for eta and kappa\n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0, shape=2)\n",
    "    \n",
    "    #    \n",
    "    k_log1 = pm.Exponential(\"k_log1\", lam=1.5)\n",
    "    k1 = pm.Deterministic(\"k1\", tt.exp(k_log1))\n",
    "    kappa = pm.Beta(\"kappa\", alpha=phi[0] * k1, beta=(1.0 - phi[0]) * k1, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 5)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    k_log2 = pm.Exponential(\"k_log2\", lam=1.5)\n",
    "    k2 = pm.Deterministic(\"k2\", tt.exp(k_log2))\n",
    "    eta = pm.Beta('', alpha=phi[1] * k2, beta=(1.0 - phi[1]) * k2, shape=n_subj)\n",
    "    \n",
    "   # kappa = pm.Beta('kappa', 1,1, shape=n_subj)\n",
    "   # eta = pm.Beta('eta', 1,1, shape=n_subj)\n",
    "    \n",
    "  #  beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    alpha = 0 * tt.ones((n_subj,2), dtype='float64')\n",
    "    assoc = 0 * tt.ones((n_subj,1), dtype='float64')\n",
    "    \n",
    "    [Qs,vec, alpha, assoc], updates = theano.scan(\n",
    "        fn=update_Q_hb,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec, alpha, assoc],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    # add associabillity\n",
    "    #assoc = pm.Deterministic('alpha', assoc)\n",
    "    \n",
    "    tr = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8f33f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[0]</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>333.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[1]</th>\n",
       "      <td>0.797</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>289.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2]</th>\n",
       "      <td>0.833</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>275.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[3]</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>224.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[4]</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.007</td>\n",
       "      <td>298.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[5]</th>\n",
       "      <td>0.859</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>284.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[6]</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>245.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[7]</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>331.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[8]</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>272.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[9]</th>\n",
       "      <td>0.812</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.009</td>\n",
       "      <td>231.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
       "[0]  0.812  0.253   0.258      1.0      0.009    0.007     333.0     497.0   \n",
       "[1]  0.797  0.272   0.174      1.0      0.012    0.008     289.0     643.0   \n",
       "[2]  0.833  0.246   0.288      1.0      0.009    0.007     275.0     307.0   \n",
       "[3]  0.859  0.201   0.436      1.0      0.007    0.006     224.0     374.0   \n",
       "[4]  0.834  0.242   0.284      1.0      0.011    0.007     298.0     595.0   \n",
       "[5]  0.859  0.220   0.377      1.0      0.011    0.008     284.0     494.0   \n",
       "[6]  0.826  0.252   0.260      1.0      0.012    0.009     245.0     417.0   \n",
       "[7]  0.856  0.209   0.396      1.0      0.008    0.006     331.0     483.0   \n",
       "[8]  0.829  0.236   0.322      1.0      0.011    0.008     272.0     780.0   \n",
       "[9]  0.812  0.260   0.218      1.0      0.013    0.009     231.0     531.0   \n",
       "\n",
       "      r_hat  \n",
       "[0]   1.01  \n",
       "[1]   1.02  \n",
       "[2]   1.02  \n",
       "[3]   1.02  \n",
       "[4]   1.01  \n",
       "[5]   1.02  \n",
       "[6]   1.02  \n",
       "[7]   1.02  \n",
       "[8]   1.02  \n",
       "[9]   1.02  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tr, var_names='')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ce1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
