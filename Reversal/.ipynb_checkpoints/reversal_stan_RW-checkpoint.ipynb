{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8c4f6",
   "metadata": {},
   "source": [
    "# Modeling Reversal Task\n",
    "\n",
    "### RW model of the reversal task in the aging experiment\n",
    "\n",
    "The aim of this notbook is to see if age affects appetative reversal learning.\n",
    "\n",
    "participants have 70 trials 40% reinforced.\n",
    "\n",
    "reversal of stimuli occurs after 35 trials.\n",
    "\n",
    "This notbook is based on Or's simulation of SCR.\n",
    "\n",
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c7023",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "make sure only participant with complete data set are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e15d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subject:  49\n"
     ]
    }
   ],
   "source": [
    "glober = '/media/Data/Lab_Projects/Aging/behavioral/Reversal/AG_*_RV/ETLearning_*.csv'\n",
    "\n",
    "db = pd.DataFrame()\n",
    "\n",
    "for sub in glob(glober):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(sub)\n",
    "        df['sub'] = sub.split('_')[2]\n",
    "        if df.shape[0] == 70:\n",
    "            \n",
    "            db = db.append(df[df.trialNum<36])\n",
    "    except:\n",
    "        print(sub)\n",
    "        print('error')\n",
    "\n",
    "#db['rating'] = db['rating'].replace(0, np.nan)\n",
    "print('number of subject: ', len(db['sub'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f026fe",
   "metadata": {},
   "source": [
    "## get descriptive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subj   = len(db['sub'].unique())\n",
    "n_trials = max(db.trialNum)\n",
    "\n",
    "trials, subj = np.meshgrid(range(n_trials), range(n_subj))\n",
    "trials = tt.as_tensor_variable(trials.T)\n",
    "subj   = tt.as_tensor_variable(subj.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de89482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim   = np.reshape([db['rectOri']],   (n_subj, n_trials)).T\n",
    "reward = np.reshape([db['rectValue']], (n_subj, n_trials)).T\n",
    "rating = np.reshape([db['rating']],    (n_subj, n_trials)).T\n",
    "\n",
    "stim   = np.array(stim/45,  dtype='int')\n",
    "reward = np.array(reward/6*9, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3681db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = tt.as_tensor_variable(stim)\n",
    "reward = tt.as_tensor_variable(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6489196c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f410ffcca30>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = db[db['sub']=='24']\n",
    "plt.plot(df.rating[df['rectOri']==45])\n",
    "plt.plot(df.rating[df['rectOri']==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf139ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e65d1b",
   "metadata": {},
   "source": [
    "# create a pymc3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457ca1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# generate functions to run\n",
    "def update_Q(stim, reward,\n",
    "             Qs,vec,\n",
    "             alpha, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by theano.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the theano.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: tt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "     \n",
    "    PE = reward - Qs[tt.arange(n_subj), stim]\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * PE)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5319763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:15<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 197 seconds.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as mB:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057f4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2509.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3672.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>2313.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3432.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.052  0.029   0.000    0.102      0.001    0.000    2777.0   \n",
       "alpha[1]   0.039  0.018   0.001    0.069      0.000    0.000    2050.0   \n",
       "alpha[2]   0.026  0.017   0.000    0.055      0.000    0.000    2583.0   \n",
       "alpha[3]   0.079  0.030   0.024    0.133      0.001    0.000    3015.0   \n",
       "alpha[4]   0.023  0.016   0.000    0.051      0.000    0.000    2598.0   \n",
       "alpha[5]   0.038  0.029   0.000    0.087      0.001    0.000    2097.0   \n",
       "alpha[6]   0.014  0.011   0.000    0.034      0.000    0.000    2840.0   \n",
       "alpha[7]   0.117  0.040   0.043    0.190      0.001    0.000    3182.0   \n",
       "alpha[8]   0.052  0.033   0.001    0.109      0.000    0.000    3450.0   \n",
       "alpha[9]   0.026  0.020   0.000    0.062      0.000    0.000    2509.0   \n",
       "alpha[10]  0.040  0.021   0.002    0.079      0.000    0.000    2939.0   \n",
       "alpha[11]  0.168  0.050   0.081    0.267      0.001    0.001    3672.0   \n",
       "alpha[12]  0.047  0.025   0.002    0.090      0.001    0.000    2090.0   \n",
       "alpha[13]  0.017  0.012   0.000    0.039      0.000    0.000    2869.0   \n",
       "alpha[14]  0.150  0.063   0.034    0.272      0.001    0.001    2261.0   \n",
       "alpha[15]  0.029  0.021   0.000    0.066      0.000    0.000    2652.0   \n",
       "alpha[16]  0.013  0.011   0.000    0.032      0.000    0.000    2477.0   \n",
       "alpha[17]  0.063  0.028   0.009    0.114      0.000    0.000    2989.0   \n",
       "alpha[18]  0.020  0.017   0.000    0.052      0.000    0.000    3432.0   \n",
       "alpha[19]  0.032  0.022   0.000    0.069      0.000    0.000    2776.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     1559.0    1.0  \n",
       "alpha[1]      910.0    1.0  \n",
       "alpha[2]     1387.0    1.0  \n",
       "alpha[3]     2009.0    1.0  \n",
       "alpha[4]     1993.0    1.0  \n",
       "alpha[5]     1444.0    1.0  \n",
       "alpha[6]     1814.0    1.0  \n",
       "alpha[7]     2321.0    1.0  \n",
       "alpha[8]     1878.0    1.0  \n",
       "alpha[9]     1725.0    1.0  \n",
       "alpha[10]    1950.0    1.0  \n",
       "alpha[11]    2480.0    1.0  \n",
       "alpha[12]    1464.0    1.0  \n",
       "alpha[13]    1915.0    1.0  \n",
       "alpha[14]    1221.0    1.0  \n",
       "alpha[15]    2313.0    1.0  \n",
       "alpha[16]    1969.0    1.0  \n",
       "alpha[17]    1854.0    1.0  \n",
       "alpha[18]    2148.0    1.0  \n",
       "alpha[19]    2253.0    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb238a8-005f-422d-bbca-54d7a147bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 197 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_I:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_I = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f6865f-eff2-4d9b-8104-11f00f9d4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.582</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4768.0</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.154</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.255</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4403.0</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.489</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.377</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3916.0</td>\n",
       "      <td>2837.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.414</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3676.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.487</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>2342.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4434.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2691.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.281</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3860.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3582.0</td>\n",
       "      <td>2637.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.448</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.410</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>3017.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.291</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3452.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.518</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6217.0</td>\n",
       "      <td>2594.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3807.0</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.582  0.262   0.123    1.000      0.004    0.003    4768.0   \n",
       "alpha[1]   0.111  0.083   0.000    0.232      0.002    0.002    3663.0   \n",
       "alpha[2]   0.154  0.104   0.000    0.332      0.002    0.001    3580.0   \n",
       "alpha[3]   0.255  0.104   0.067    0.451      0.002    0.001    4403.0   \n",
       "alpha[4]   0.115  0.088   0.000    0.273      0.001    0.001    3680.0   \n",
       "alpha[5]   0.489  0.226   0.085    0.924      0.004    0.003    3286.0   \n",
       "alpha[6]   0.377  0.297   0.000    0.891      0.005    0.004    3916.0   \n",
       "alpha[7]   0.414  0.151   0.143    0.705      0.003    0.002    3676.0   \n",
       "alpha[8]   0.487  0.285   0.005    0.932      0.004    0.003    5430.0   \n",
       "alpha[9]   0.469  0.283   0.000    0.923      0.004    0.003    4434.0   \n",
       "alpha[10]  0.294  0.234   0.000    0.794      0.005    0.004    2691.0   \n",
       "alpha[11]  0.470  0.206   0.128    0.904      0.004    0.003    3312.0   \n",
       "alpha[12]  0.281  0.159   0.025    0.571      0.003    0.002    3248.0   \n",
       "alpha[13]  0.054  0.045   0.000    0.132      0.001    0.001    3860.0   \n",
       "alpha[14]  0.412  0.302   0.000    0.915      0.005    0.004    3582.0   \n",
       "alpha[15]  0.448  0.226   0.028    0.851      0.004    0.003    3504.0   \n",
       "alpha[16]  0.410  0.313   0.001    0.916      0.007    0.005    1907.0   \n",
       "alpha[17]  0.291  0.149   0.057    0.583      0.003    0.002    3452.0   \n",
       "alpha[18]  0.518  0.282   0.083    0.999      0.003    0.003    6217.0   \n",
       "alpha[19]  0.361  0.272   0.001    0.869      0.005    0.004    3807.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     2391.0    1.0  \n",
       "alpha[1]     1934.0    1.0  \n",
       "alpha[2]     1938.0    1.0  \n",
       "alpha[3]     2060.0    1.0  \n",
       "alpha[4]     1699.0    1.0  \n",
       "alpha[5]     1919.0    1.0  \n",
       "alpha[6]     2837.0    1.0  \n",
       "alpha[7]     1943.0    1.0  \n",
       "alpha[8]     2342.0    1.0  \n",
       "alpha[9]     2601.0    1.0  \n",
       "alpha[10]    1825.0    1.0  \n",
       "alpha[11]    1845.0    1.0  \n",
       "alpha[12]    2340.0    1.0  \n",
       "alpha[13]    2095.0    1.0  \n",
       "alpha[14]    2637.0    1.0  \n",
       "alpha[15]    2223.0    1.0  \n",
       "alpha[16]    3017.0    1.0  \n",
       "alpha[17]    2230.0    1.0  \n",
       "alpha[18]    2594.0    1.0  \n",
       "alpha[19]    2334.0    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_I, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125ae433-0091-4b97-ba95-b489803d1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/arviz/stats/stats.py:694: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>-4101.342000</td>\n",
       "      <td>81.081250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862673</td>\n",
       "      <td>25.667963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>-4142.566014</td>\n",
       "      <td>74.514335</td>\n",
       "      <td>41.224014</td>\n",
       "      <td>0.137327</td>\n",
       "      <td>22.974535</td>\n",
       "      <td>10.713163</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo      p_loo      d_loo    weight         se  \\\n",
       "model1     0 -4101.342000  81.081250   0.000000  0.862673  25.667963   \n",
       "model2     1 -4142.566014  74.514335  41.224014  0.137327  22.974535   \n",
       "\n",
       "              dse  warning loo_scale  \n",
       "model1   0.000000     True       log  \n",
       "model2  10.713163    False       log  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bbfd10-7229-4a13-b3a6-473e50cee83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 14:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 899 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_Is:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_Is = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4143cb4-6339-4b21-955b-f11e20689065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.343</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.165</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.284</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2986.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.338</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.276</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.289</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.383</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.208</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.251</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.343  0.324   0.000    0.907      0.007    0.005    2039.0   \n",
       "alpha[1]   0.144  0.210   0.000    0.629      0.004    0.003    2591.0   \n",
       "alpha[2]   0.271  0.242   0.000    0.744      0.004    0.003    2157.0   \n",
       "alpha[3]   0.165  0.116   0.009    0.369      0.002    0.001    3401.0   \n",
       "alpha[4]   0.284  0.266   0.000    0.808      0.005    0.004    1565.0   \n",
       "alpha[5]   0.404  0.239   0.000    0.814      0.004    0.003    2986.0   \n",
       "alpha[6]   0.338  0.284   0.000    0.874      0.005    0.004    2056.0   \n",
       "alpha[7]   0.276  0.142   0.040    0.528      0.002    0.002    3666.0   \n",
       "alpha[8]   0.289  0.278   0.000    0.848      0.005    0.004    1698.0   \n",
       "alpha[9]   0.383  0.294   0.000    0.889      0.007    0.005    1535.0   \n",
       "alpha[10]  0.238  0.259   0.000    0.802      0.004    0.003    2733.0   \n",
       "alpha[11]  0.199  0.099   0.040    0.375      0.001    0.001    3750.0   \n",
       "alpha[12]  0.243  0.218   0.000    0.668      0.004    0.003    2206.0   \n",
       "alpha[13]  0.307  0.289   0.000    0.858      0.006    0.004    1992.0   \n",
       "alpha[14]  0.208  0.147   0.002    0.466      0.003    0.002    2819.0   \n",
       "alpha[15]  0.525  0.263   0.000    0.922      0.006    0.004    1808.0   \n",
       "alpha[16]  0.407  0.219   0.000    0.816      0.004    0.003    2604.0   \n",
       "alpha[17]  0.251  0.203   0.000    0.647      0.003    0.002    2915.0   \n",
       "alpha[18]  0.395  0.304   0.000    0.904      0.007    0.005    1516.0   \n",
       "alpha[19]  0.315  0.288   0.000    0.867      0.005    0.004    2057.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     2544.0    1.0  \n",
       "alpha[1]     1777.0    1.0  \n",
       "alpha[2]     2145.0    1.0  \n",
       "alpha[3]     2059.0    1.0  \n",
       "alpha[4]     1929.0    1.0  \n",
       "alpha[5]     1579.0    1.0  \n",
       "alpha[6]     1434.0    1.0  \n",
       "alpha[7]     1932.0    1.0  \n",
       "alpha[8]     2085.0    1.0  \n",
       "alpha[9]     1608.0    1.0  \n",
       "alpha[10]    2064.0    1.0  \n",
       "alpha[11]    2160.0    1.0  \n",
       "alpha[12]    1890.0    1.0  \n",
       "alpha[13]    1819.0    1.0  \n",
       "alpha[14]    1769.0    1.0  \n",
       "alpha[15]     676.0    1.0  \n",
       "alpha[16]    1001.0    1.0  \n",
       "alpha[17]    2033.0    1.0  \n",
       "alpha[18]    1064.0    1.0  \n",
       "alpha[19]    2208.0    1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_Is, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a2e330-0b72-4599-8578-e228d3dfa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/arviz/stats/stats.py:694: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0</td>\n",
       "      <td>-4098.001929</td>\n",
       "      <td>106.029952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.897614e-01</td>\n",
       "      <td>25.380207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4101.342000</td>\n",
       "      <td>81.081250</td>\n",
       "      <td>3.340071</td>\n",
       "      <td>4.102386e-01</td>\n",
       "      <td>25.667963</td>\n",
       "      <td>6.829368</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>2</td>\n",
       "      <td>-4142.566014</td>\n",
       "      <td>74.514335</td>\n",
       "      <td>44.564086</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>22.974535</td>\n",
       "      <td>9.116228</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo       p_loo      d_loo        weight         se  \\\n",
       "model3     0 -4098.001929  106.029952   0.000000  5.897614e-01  25.380207   \n",
       "model1     1 -4101.342000   81.081250   3.340071  4.102386e-01  25.667963   \n",
       "model2     2 -4142.566014   74.514335  44.564086  9.992007e-16  22.974535   \n",
       "\n",
       "             dse  warning loo_scale  \n",
       "model3  0.000000    False       log  \n",
       "model1  6.829368     True       log  \n",
       "model2  9.116228    False       log  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I, 'model3':trB_Is})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddbe8f",
   "metadata": {},
   "source": [
    "## hierarchal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd609241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 8 jobs)\n",
      "NUTS: [eps, beta, beta_sd, beta_h, alpha, kappa_log, phi, intercept_matt, sd, mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 32:24<00:00 Sampling 4 chains, 473 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1946 seconds.\n",
      "There were 23 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9612888080508708, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "There were 198 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8168502366291275, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "There were 135 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 117 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as m_H:\n",
    "    \n",
    "    # intercept\n",
    "    mu = pm.Normal('mu', 0, 1)\n",
    "    sd = pm.HalfNormal('sd',5) \n",
    "    intercept_matt = pm.Normal('intercept_matt', mu=0, sd=1, shape=n_subj)\n",
    "    intercept = pm.Deterministic('intercept',intercept_matt + mu*sd)\n",
    "    \n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0)\n",
    "\n",
    "    kappa_log = pm.Exponential(\"kappa_log\", lam=1.5)\n",
    "    kappa = pm.Deterministic(\"kappa\", tt.exp(kappa_log))\n",
    "\n",
    "    alpha = pm.Beta(\"alpha\", alpha=phi * kappa, beta=(1.0 - phi) * kappa, shape=n_subj)\n",
    "    \n",
    "    \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 1)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "       \n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec0 = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec0],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "     \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_hB = pm.sample(target_accept=.9, chains=4, cores=8, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3c60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>579.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>970.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>522.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>578.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>681.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>570.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>328.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>867.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>722.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]  0.048  0.034   0.000    0.108      0.001    0.001     579.0   \n",
       "alpha[1]  0.032  0.026   0.000    0.077      0.001    0.000     970.0   \n",
       "alpha[2]  0.024  0.029   0.000    0.073      0.001    0.001     522.0   \n",
       "alpha[3]  0.092  0.060   0.000    0.195      0.002    0.002     578.0   \n",
       "alpha[4]  0.017  0.023   0.000    0.056      0.001    0.001     681.0   \n",
       "alpha[5]  0.047  0.065   0.000    0.166      0.002    0.002     570.0   \n",
       "alpha[6]  0.010  0.016   0.000    0.032      0.000    0.000     637.0   \n",
       "alpha[7]  0.157  0.087   0.014    0.317      0.004    0.003     328.0   \n",
       "alpha[8]  0.047  0.044   0.000    0.121      0.002    0.002     867.0   \n",
       "alpha[9]  0.020  0.023   0.000    0.063      0.001    0.000     722.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "alpha[0]     561.0   1.01  \n",
       "alpha[1]     611.0   1.00  \n",
       "alpha[2]     544.0   1.01  \n",
       "alpha[3]     925.0   1.01  \n",
       "alpha[4]     900.0   1.00  \n",
       "alpha[5]     540.0   1.01  \n",
       "alpha[6]    1001.0   1.00  \n",
       "alpha[7]     993.0   1.02  \n",
       "alpha[8]     874.0   1.01  \n",
       "alpha[9]     837.0   1.01  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tr_hB, var_names='alpha')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b224f3",
   "metadata": {},
   "source": [
    "## model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18dd6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/arviz/stats/stats.py:694: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0</td>\n",
       "      <td>-4085.274658</td>\n",
       "      <td>66.166883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>23.379180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4101.342000</td>\n",
       "      <td>81.081250</td>\n",
       "      <td>16.067343</td>\n",
       "      <td>6.554757e-13</td>\n",
       "      <td>25.667963</td>\n",
       "      <td>5.445579</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo      p_loo      d_loo        weight         se  \\\n",
       "model2     0 -4085.274658  66.166883   0.000000  1.000000e+00  23.379180   \n",
       "model1     1 -4101.342000  81.081250  16.067343  6.554757e-13  25.667963   \n",
       "\n",
       "             dse  warning loo_scale  \n",
       "model2  0.000000    False       log  \n",
       "model1  5.445579     True       log  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = az.compare({'model1':trB, 'model2': tr_hB}, ic='loo')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b706a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Log'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_compare(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a52b65",
   "metadata": {},
   "source": [
    "## Correlate expected value and subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44411662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 49)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = trB.posterior.stack(draws=('chain','draw'))\n",
    "a = a.expected_value\n",
    "mean_a = np.mean(a, axis=2)\n",
    "mean_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "400bdd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.27892827168710455, 0.1046705904167483)\n",
      "(0.3780308551516219, 0.0251521131189318)\n",
      "(0.146632848682171, 0.40060357184691947)\n",
      "(0.5043119470447103, 0.0020075948139449185)\n",
      "(0.103949771127254, 0.5523419431558565)\n",
      "(0.09714864186687253, 0.5787700805757358)\n",
      "(-0.19253298712026426, 0.26782704952544334)\n",
      "(0.3829978955931457, 0.023151390120439947)\n",
      "(0.3697169110796787, 0.02881916008784062)\n",
      "(0.014020547755306584, 0.936286498769684)\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    cor1 = scipy.stats.pearsonr(rating[:,i], mean_a[:,i])\n",
    "    print(cor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc336ba9",
   "metadata": {},
   "source": [
    "## The Pearce-Hall Hybrid model\n",
    "\n",
    "This is Or's attempt to build the PH Hybrid model. This model doesn't assume a simple constant learning rate (as the RW), rather, it incorporated both a constant learning rate and a dynamic one. The dynamic one is being updated by the amount of new information given. The model goes like that: \n",
    "\n",
    "(1) Vi(k+1) = Vi (k) + (k) + (k)\n",
    "\n",
    "(2)  = shock - Vi(k) \n",
    "\n",
    "(3) (k+1) = || + (1-)(k)\n",
    "\n",
    "So the current value is an update of the previous one plus a constant learning rate (kappa) and an associability weight (alpha) (times the delta = prediction error).\n",
    "\n",
    "The  is set by a constant weight of associability (eta) and the previous .\n",
    "\n",
    "So now, our updating function will include those elements as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7fde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate functions to run\n",
    "def update_Q_hb(stim, shock,\n",
    "             Qs,vec,alpha,assoc,\n",
    "             eta,kappa, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to Hybrid PH model\n",
    "    For information, please see this paper: https://www.sciencedirect.com/science/article/pii/S0896627316305840?via%3Dihub\n",
    "  \n",
    "    \"\"\"\n",
    "      \n",
    "    delta = shock - Qs[tt.arange(n_subj), stim]\n",
    "    alpha = tt.set_subtensor(alpha[tt.arange(n_subj), stim], eta * abs(delta) + (1-eta)*alpha[tt.arange(n_subj), stim])\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + kappa*alpha[tt.arange(n_subj), stim] * delta)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    # we use the same idea to get the associability per trial\n",
    "    assoc = tt.set_subtensor(assoc[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                alpha[tt.arange(n_subj),1], alpha[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec, alpha, assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae9b4457",
   "metadata": {},
   "outputs": [
    {
     "ename": "SamplingError",
     "evalue": "Initial evaluation of model at starting point failed!\nStarting values:\n{'phi_interval__': array([0., 0.]), 'intercept': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log1_log__': array(-0.77197803), 'kappa_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'beta_h': array(0.), 'beta_sd_log__': array(1.38364656), 'beta': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log2_log__': array(-0.77197803), '_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'eps_log__': array(1.38364656)}\n\nInitial evaluation results:\nphi_interval__      -2.77\nintercept         -123.89\nk_log1_log__        -1.06\nkappa_logodds__    -75.01\nbeta_h              -0.92\nbeta_sd_log__       -0.77\nbeta              -112.83\nk_log2_log__        -1.06\n_logodds__        -75.01\neps_log__           -0.77\nscrs                  NaN\nName: Log-probability of test_point, dtype: float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22753/3985315658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m#assoc = pm.Deterministic('alpha', assoc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_accept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inferencedata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mcheck_start_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/util.py\u001b[0m in \u001b[0;36mcheck_start_vals\u001b[0;34m(start, model)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             raise SamplingError(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;34m\"Initial evaluation of model at starting point failed!\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;34m\"Starting values:\\n{}\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSamplingError\u001b[0m: Initial evaluation of model at starting point failed!\nStarting values:\n{'phi_interval__': array([0., 0.]), 'intercept': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log1_log__': array(-0.77197803), 'kappa_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'beta_h': array(0.), 'beta_sd_log__': array(1.38364656), 'beta': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log2_log__': array(-0.77197803), '_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'eps_log__': array(1.38364656)}\n\nInitial evaluation results:\nphi_interval__      -2.77\nintercept         -123.89\nk_log1_log__        -1.06\nkappa_logodds__    -75.01\nbeta_h              -0.92\nbeta_sd_log__       -0.77\nbeta              -112.83\nk_log2_log__        -1.06\n_logodds__        -75.01\neps_log__           -0.77\nscrs                  NaN\nName: Log-probability of test_point, dtype: float64"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "  \n",
    "    # hyperpriors for eta and kappa\n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0, shape=2)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    #    \n",
    "    k_log1 = pm.Exponential(\"k_log1\", lam=1.5)\n",
    "    k1 = pm.Deterministic(\"k1\", tt.exp(k_log1))\n",
    "    kappa = pm.Beta(\"kappa\", alpha=phi[0] * k1, beta=(1.0 - phi[0]) * k1, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 5)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    k_log2 = pm.Exponential(\"k_log2\", lam=1.5)\n",
    "    k2 = pm.Deterministic(\"k2\", tt.exp(k_log2))\n",
    "    eta = pm.Beta('', alpha=phi[1] * k2, beta=(1.0 - phi[1]) * k2, shape=n_subj)\n",
    "    \n",
    "   # kappa = pm.Beta('kappa', 1,1, shape=n_subj)\n",
    "   # eta = pm.Beta('eta', 1,1, shape=n_subj)\n",
    "    \n",
    "  #  beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    alpha = 0 * tt.ones((n_subj,2), dtype='float64')\n",
    "    assoc = 0 * tt.ones((n_subj,1), dtype='float64')\n",
    "    \n",
    "    [Qs,vec, alpha, assoc], updates = theano.scan(\n",
    "        fn=update_Q_hb,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec, alpha, assoc],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    # add associabillity\n",
    "    #assoc = pm.Deterministic('alpha', assoc)\n",
    "    \n",
    "    tr = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f33f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(tr, var_names='')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ce1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
