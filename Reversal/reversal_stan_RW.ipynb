{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8c4f6",
   "metadata": {},
   "source": [
    "# Modeling Reversal Task\n",
    "\n",
    "### RW model of the reversal task in the aging experiment\n",
    "\n",
    "The aim of this notbook is to see if age affects appetative reversal learning.\n",
    "\n",
    "participants have 70 trials 40% reinforced.\n",
    "\n",
    "reversal of stimuli occurs after 35 trials.\n",
    "\n",
    "This notbook is based on Or's simulation of SCR.\n",
    "\n",
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "import pingouin as pg\n",
    "import os\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c7023",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "make sure only participant with complete data set are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e15d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subject:  72\n"
     ]
    }
   ],
   "source": [
    "glober = '/media/Data/Lab_Projects/Aging/behavioral/Reversal/AG_*_RV/ETLearning_*.csv'\n",
    "\n",
    "db = pd.DataFrame()\n",
    "\n",
    "for sub in glob(glober):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(sub)\n",
    "        df['sub'] = sub.split('_')[2]\n",
    "        if df.shape[0] == 70:\n",
    "            db = pd.concat([db, df], axis = 0)\n",
    "            #db = db.append(df)#[df.trialNum<36])\n",
    "    except:\n",
    "        print(sub)\n",
    "        print('error')\n",
    "\n",
    "#db['rating'] = db['rating'].replace(0, np.nan)\n",
    "db = db.sort_values(by=['sub','trialNum'])\n",
    "print('number of subject: ', len(db['sub'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d96f4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of participants with age and moca scores:  63\n"
     ]
    }
   ],
   "source": [
    "age = pd.read_excel('/media/Data/Lab_Projects/Aging/aging_session_log.xlsx', sheet_name='sessions').iloc[:,[0,7,9]]\n",
    "moca = pd.read_excel('/media/Data/Lab_Projects/Aging/aging_session_log.xlsx', sheet_name='assessments').iloc[:,[0,22]]\n",
    "\n",
    "age.columns.values[0] = \"sub\"\n",
    "moca.columns.values[0] = \"sub\"\n",
    "age = age[age.gender != 'gender']\n",
    "age = age.dropna().reset_index()\n",
    "age = age.drop(['index'], axis=1)\n",
    "\n",
    "age = age.merge(moca, left_on='sub', right_on='sub')\n",
    "age['sub'] = age['sub'].map(lambda x: int(x.lstrip('AG_')))\n",
    "print(\"number of participants with age and moca scores: \",age.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74d8b681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid subjects:  47\n"
     ]
    }
   ],
   "source": [
    "db['sub'] = db['sub'].astype('int')\n",
    "db = db.merge(age, left_on='sub', right_on='sub')\n",
    "db = db[db.moca_score >25]\n",
    "print('Valid subjects: ', len(np.unique(db['sub'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f026fe",
   "metadata": {},
   "source": [
    "## get descriptive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d26b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subj   = len(db['sub'].unique())\n",
    "n_trials = max(db.trialNum)\n",
    "\n",
    "trials, subj = np.meshgrid(range(n_trials), range(n_subj))\n",
    "trials = tt.as_tensor_variable(trials.T)\n",
    "subj   = tt.as_tensor_variable(subj.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de89482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim   = np.reshape([db['rectOri']],   (n_subj, n_trials)).T\n",
    "reward = np.reshape([db['rectValue']], (n_subj, n_trials)).T\n",
    "rating = np.reshape([db['rating']],    (n_subj, n_trials)).T\n",
    "\n",
    "stim   = np.array(stim/45,  dtype='int')\n",
    "reward = np.array(reward/6*9, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b3681db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = tt.as_tensor_variable(stim)\n",
    "reward = tt.as_tensor_variable(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e65d1b",
   "metadata": {},
   "source": [
    "# create a pymc3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "457ca1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# generate functions to run\n",
    "def update_Q(stim, reward,\n",
    "             Qs,vec,\n",
    "             alpha, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by theano.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the theano.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: tt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "     \n",
    "    PE = reward - Qs[tt.arange(n_subj), stim]\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * PE)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5319763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 17:12<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1035 seconds.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as mB:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "057f4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3895.0</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>2510.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3218.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4256.0</td>\n",
       "      <td>2461.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>1771.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4916.0</td>\n",
       "      <td>3031.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3582.0</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3402.0</td>\n",
       "      <td>2155.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3481.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2239.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4575.0</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7454.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4828.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4983.0</td>\n",
       "      <td>2229.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4129.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3649.0</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3834.0</td>\n",
       "      <td>2507.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3009.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3795.0</td>\n",
       "      <td>2694.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.024  0.018   0.000    0.056        0.0      0.0    3895.0   \n",
       "alpha[1]   0.024  0.010   0.006    0.044        0.0      0.0    5571.0   \n",
       "alpha[2]   0.006  0.005   0.000    0.015        0.0      0.0    3218.0   \n",
       "alpha[3]   0.029  0.020   0.000    0.065        0.0      0.0    4256.0   \n",
       "alpha[4]   0.022  0.010   0.003    0.039        0.0      0.0    3458.0   \n",
       "alpha[5]   0.013  0.011   0.000    0.033        0.0      0.0    4916.0   \n",
       "alpha[6]   0.006  0.005   0.000    0.016        0.0      0.0    3582.0   \n",
       "alpha[7]   0.004  0.004   0.000    0.011        0.0      0.0    3402.0   \n",
       "alpha[8]   0.011  0.009   0.000    0.027        0.0      0.0    3481.0   \n",
       "alpha[9]   0.016  0.012   0.000    0.037        0.0      0.0    4300.0   \n",
       "alpha[10]  0.028  0.016   0.000    0.056        0.0      0.0    4575.0   \n",
       "alpha[11]  0.130  0.031   0.073    0.190        0.0      0.0    7454.0   \n",
       "alpha[12]  0.024  0.011   0.004    0.044        0.0      0.0    4828.0   \n",
       "alpha[13]  0.015  0.008   0.001    0.028        0.0      0.0    4983.0   \n",
       "alpha[14]  0.072  0.029   0.020    0.127        0.0      0.0    4129.0   \n",
       "alpha[15]  0.011  0.010   0.000    0.028        0.0      0.0    3649.0   \n",
       "alpha[16]  0.006  0.005   0.000    0.015        0.0      0.0    3834.0   \n",
       "alpha[17]  0.033  0.017   0.002    0.065        0.0      0.0    3009.0   \n",
       "alpha[18]  0.004  0.004   0.000    0.011        0.0      0.0    3795.0   \n",
       "alpha[19]  0.010  0.008   0.000    0.024        0.0      0.0    3551.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     2138.0    1.0  \n",
       "alpha[1]     2510.0    1.0  \n",
       "alpha[2]     2208.0    1.0  \n",
       "alpha[3]     2461.0    1.0  \n",
       "alpha[4]     1771.0    1.0  \n",
       "alpha[5]     3031.0    1.0  \n",
       "alpha[6]     2455.0    1.0  \n",
       "alpha[7]     2155.0    1.0  \n",
       "alpha[8]     2064.0    1.0  \n",
       "alpha[9]     2239.0    1.0  \n",
       "alpha[10]    2220.0    1.0  \n",
       "alpha[11]    2836.0    1.0  \n",
       "alpha[12]    2656.0    1.0  \n",
       "alpha[13]    2229.0    1.0  \n",
       "alpha[14]    2238.0    1.0  \n",
       "alpha[15]    2301.0    1.0  \n",
       "alpha[16]    2507.0    1.0  \n",
       "alpha[17]    1268.0    1.0  \n",
       "alpha[18]    2694.0    1.0  \n",
       "alpha[19]    2189.0    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb238a8-005f-422d-bbca-54d7a147bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 13:47<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 829 seconds.\n",
      "The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_I:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_I = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f6865f-eff2-4d9b-8104-11f00f9d4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>883.0</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>1879.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2950.0</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1714.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.453</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2801.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.390</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.421</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1647.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.345</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>2283.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.562</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.327</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.124</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.013</td>\n",
       "      <td>232.0</td>\n",
       "      <td>895.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.363</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.398</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.437</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.008</td>\n",
       "      <td>733.0</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.258</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1453.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4782.0</td>\n",
       "      <td>2523.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.451</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2831.0</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.469  0.272   0.000    0.875      0.010    0.007     883.0   \n",
       "alpha[1]   0.115  0.116   0.001    0.275      0.004    0.003    1563.0   \n",
       "alpha[2]   0.085  0.079   0.000    0.226      0.002    0.002    1226.0   \n",
       "alpha[3]   0.296  0.099   0.121    0.479      0.002    0.001    2950.0   \n",
       "alpha[4]   0.094  0.091   0.001    0.201      0.003    0.002    1714.0   \n",
       "alpha[5]   0.453  0.268   0.000    0.916      0.005    0.004    2801.0   \n",
       "alpha[6]   0.390  0.240   0.003    0.827      0.006    0.004    1981.0   \n",
       "alpha[7]   0.421  0.107   0.228    0.628      0.003    0.002    1647.0   \n",
       "alpha[8]   0.345  0.255   0.000    0.819      0.006    0.005    1697.0   \n",
       "alpha[9]   0.562  0.246   0.126    0.996      0.004    0.003    3125.0   \n",
       "alpha[10]  0.327  0.243   0.003    0.837      0.007    0.005    1366.0   \n",
       "alpha[11]  0.124  0.243   0.000    0.734      0.018    0.013     232.0   \n",
       "alpha[12]  0.363  0.271   0.004    0.880      0.007    0.005    1268.0   \n",
       "alpha[13]  0.069  0.058   0.000    0.155      0.001    0.001    1921.0   \n",
       "alpha[14]  0.033  0.097   0.000    0.075      0.003    0.002    1556.0   \n",
       "alpha[15]  0.398  0.152   0.131    0.693      0.004    0.003    1711.0   \n",
       "alpha[16]  0.437  0.314   0.000    0.936      0.011    0.008     733.0   \n",
       "alpha[17]  0.258  0.141   0.048    0.526      0.004    0.003    1453.0   \n",
       "alpha[18]  0.472  0.274   0.032    0.943      0.004    0.003    4782.0   \n",
       "alpha[19]  0.451  0.294   0.000    0.928      0.005    0.004    2831.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     1514.0   1.01  \n",
       "alpha[1]      856.0   1.00  \n",
       "alpha[2]     1879.0   1.00  \n",
       "alpha[3]     2508.0   1.00  \n",
       "alpha[4]     1349.0   1.00  \n",
       "alpha[5]     2208.0   1.00  \n",
       "alpha[6]     1615.0   1.00  \n",
       "alpha[7]     2021.0   1.00  \n",
       "alpha[8]     2283.0   1.01  \n",
       "alpha[9]     2059.0   1.00  \n",
       "alpha[10]    2129.0   1.00  \n",
       "alpha[11]     895.0   1.02  \n",
       "alpha[12]    2339.0   1.01  \n",
       "alpha[13]    1957.0   1.00  \n",
       "alpha[14]     903.0   1.00  \n",
       "alpha[15]    1099.0   1.00  \n",
       "alpha[16]    1653.0   1.01  \n",
       "alpha[17]    1499.0   1.01  \n",
       "alpha[18]    2523.0   1.00  \n",
       "alpha[19]    2258.0   1.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_I, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125ae433-0091-4b97-ba95-b489803d1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:145: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:655: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>-11977.564927</td>\n",
       "      <td>113.574510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757643</td>\n",
       "      <td>41.082523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>-12061.238900</td>\n",
       "      <td>119.857351</td>\n",
       "      <td>83.673974</td>\n",
       "      <td>0.242357</td>\n",
       "      <td>38.566724</td>\n",
       "      <td>18.721937</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank           loo       p_loo      d_loo    weight         se  \\\n",
       "model1     0 -11977.564927  113.574510   0.000000  0.757643  41.082523   \n",
       "model2     1 -12061.238900  119.857351  83.673974  0.242357  38.566724   \n",
       "\n",
       "              dse  warning loo_scale  \n",
       "model1   0.000000    False       log  \n",
       "model2  18.721937     True       log  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05bbfd10-7229-4a13-b3a6-473e50cee83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 1:01:43<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3704 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with random intercept\n",
    "with pm.Model() as mB_Is:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    rates = pm.Normal('rates', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_Is = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4143cb4-6339-4b21-955b-f11e20689065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.531</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4137.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.457</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>951.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5122.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.155</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.135</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.355</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1595.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.264</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5086.0</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2647.0</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.420</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.432</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2864.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.062</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2735.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.370</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>2463.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.229</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2698.0</td>\n",
       "      <td>1757.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.504</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.169</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.339  0.238   0.000    0.782      0.005    0.004    1390.0   \n",
       "alpha[1]   0.531  0.139   0.288    0.808      0.002    0.002    4137.0   \n",
       "alpha[2]   0.100  0.184   0.000    0.517      0.005    0.004    2017.0   \n",
       "alpha[3]   0.457  0.318   0.000    0.923      0.010    0.007     951.0   \n",
       "alpha[4]   0.259  0.094   0.093    0.427      0.001    0.001    5122.0   \n",
       "alpha[5]   0.356  0.280   0.000    0.859      0.006    0.004    1920.0   \n",
       "alpha[6]   0.155  0.163   0.000    0.454      0.004    0.003    1961.0   \n",
       "alpha[7]   0.135  0.227   0.000    0.714      0.004    0.003    2967.0   \n",
       "alpha[8]   0.355  0.293   0.000    0.886      0.006    0.004    1595.0   \n",
       "alpha[9]   0.264  0.307   0.000    0.887      0.006    0.004    1734.0   \n",
       "alpha[10]  0.146  0.047   0.066    0.238      0.001    0.000    5086.0   \n",
       "alpha[11]  0.105  0.132   0.001    0.251      0.003    0.002    2647.0   \n",
       "alpha[12]  0.420  0.181   0.136    0.825      0.003    0.003    3196.0   \n",
       "alpha[13]  0.432  0.258   0.004    0.896      0.004    0.003    2864.0   \n",
       "alpha[14]  0.062  0.116   0.003    0.129      0.003    0.002    2735.0   \n",
       "alpha[15]  0.370  0.295   0.000    0.891      0.007    0.005    1026.0   \n",
       "alpha[16]  0.085  0.027   0.041    0.139      0.000    0.000    3480.0   \n",
       "alpha[17]  0.229  0.209   0.000    0.654      0.004    0.003    2698.0   \n",
       "alpha[18]  0.504  0.264   0.074    0.981      0.006    0.004    1349.0   \n",
       "alpha[19]  0.169  0.085   0.034    0.312      0.002    0.001    2401.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]      674.0    1.0  \n",
       "alpha[1]     2028.0    1.0  \n",
       "alpha[2]     1910.0    1.0  \n",
       "alpha[3]      903.0    1.0  \n",
       "alpha[4]     2607.0    1.0  \n",
       "alpha[5]     1490.0    1.0  \n",
       "alpha[6]     1433.0    1.0  \n",
       "alpha[7]     2129.0    1.0  \n",
       "alpha[8]     1102.0    1.0  \n",
       "alpha[9]     1941.0    1.0  \n",
       "alpha[10]    2627.0    1.0  \n",
       "alpha[11]    1684.0    1.0  \n",
       "alpha[12]    1654.0    1.0  \n",
       "alpha[13]    1639.0    1.0  \n",
       "alpha[14]    1128.0    1.0  \n",
       "alpha[15]     744.0    1.0  \n",
       "alpha[16]    2463.0    1.0  \n",
       "alpha[17]    1757.0    1.0  \n",
       "alpha[18]     567.0    1.0  \n",
       "alpha[19]    1502.0    1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_Is, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44a2e330-0b72-4599-8578-e228d3dfa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:145: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:655: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0</td>\n",
       "      <td>-11927.134520</td>\n",
       "      <td>172.814712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770465</td>\n",
       "      <td>42.253480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-11977.564927</td>\n",
       "      <td>113.574510</td>\n",
       "      <td>50.430407</td>\n",
       "      <td>0.210247</td>\n",
       "      <td>41.082523</td>\n",
       "      <td>13.799741</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>2</td>\n",
       "      <td>-12061.238900</td>\n",
       "      <td>119.857351</td>\n",
       "      <td>134.104381</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>38.566724</td>\n",
       "      <td>17.207161</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank           loo       p_loo       d_loo    weight         se  \\\n",
       "model3     0 -11927.134520  172.814712    0.000000  0.770465  42.253480   \n",
       "model1     1 -11977.564927  113.574510   50.430407  0.210247  41.082523   \n",
       "model2     2 -12061.238900  119.857351  134.104381  0.019288  38.566724   \n",
       "\n",
       "              dse  warning loo_scale  \n",
       "model3   0.000000    False       log  \n",
       "model1  13.799741    False       log  \n",
       "model2  17.207161     True       log  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I, 'model3':trB_Is})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddbe8f",
   "metadata": {},
   "source": [
    "## hierarchal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd609241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 8 jobs)\n",
      "NUTS: [eps, beta, beta_sd, beta_h, alpha, kappa_log, phi, intercept_matt, sd, mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 1:51:09<00:00 Sampling 4 chains, 593 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 6671 seconds.\n",
      "There were 188 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 92 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 198 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 115 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.2 for some parameters.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as m_H:\n",
    "    \n",
    "    # intercept\n",
    "    mu = pm.Normal('mu', 0, 1)\n",
    "    sd = pm.HalfNormal('sd',5) \n",
    "    intercept_matt = pm.Normal('intercept_matt', mu=0, sd=1, shape=n_subj)\n",
    "    intercept = pm.Deterministic('intercept',intercept_matt + mu*sd)\n",
    "    \n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0)\n",
    "\n",
    "    kappa_log = pm.Exponential(\"kappa_log\", lam=1.5)\n",
    "    kappa = pm.Deterministic(\"kappa\", tt.exp(kappa_log))\n",
    "\n",
    "    alpha = pm.Beta(\"alpha\", alpha=phi * kappa, beta=(1.0 - phi) * kappa, shape=n_subj)\n",
    "    \n",
    "    \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 1)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "       \n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec0 = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec0],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "     \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_hB = pm.sample(target_accept=.9, chains=4, cores=8, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd3c60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>287.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>191.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>450.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>71.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>252.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>254.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>257.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>274.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>396.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]  0.015  0.022     0.0    0.060      0.001    0.001     287.0   \n",
       "alpha[1]  0.017  0.018     0.0    0.049      0.001    0.001     191.0   \n",
       "alpha[2]  0.002  0.005     0.0    0.009      0.000    0.000     450.0   \n",
       "alpha[3]  0.100  0.094     0.0    0.258      0.012    0.009      71.0   \n",
       "alpha[4]  0.017  0.017     0.0    0.048      0.001    0.001     252.0   \n",
       "alpha[5]  0.009  0.024     0.0    0.038      0.001    0.001     254.0   \n",
       "alpha[6]  0.002  0.006     0.0    0.008      0.000    0.000     257.0   \n",
       "alpha[7]  0.006  0.041     0.0    0.006      0.003    0.002     274.0   \n",
       "alpha[8]  0.005  0.010     0.0    0.019      0.000    0.000     396.0   \n",
       "alpha[9]  0.009  0.015     0.0    0.034      0.001    0.000     250.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "alpha[0]     331.0   1.01  \n",
       "alpha[1]     180.0   1.02  \n",
       "alpha[2]     614.0   1.00  \n",
       "alpha[3]     162.0   1.05  \n",
       "alpha[4]     283.0   1.01  \n",
       "alpha[5]     570.0   1.02  \n",
       "alpha[6]     362.0   1.01  \n",
       "alpha[7]     437.0   1.01  \n",
       "alpha[8]     646.0   1.01  \n",
       "alpha[9]     384.0   1.02  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tr_hB, var_names='alpha')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b224f3",
   "metadata": {},
   "source": [
    "## model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18dd6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:145: UserWarning: The default method used to estimate the weights for each model,has changed from BB-pseudo-BMA to stacking\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:655: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:655: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n",
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.10/site-packages/arviz/stats/stats.py:212: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ics = ics.append([ic_func(dataset, pointwise=True, scale=scale)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0</td>\n",
       "      <td>-11927.134520</td>\n",
       "      <td>172.814712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.499761e-01</td>\n",
       "      <td>42.253480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>1</td>\n",
       "      <td>-11945.350051</td>\n",
       "      <td>106.596280</td>\n",
       "      <td>18.215531</td>\n",
       "      <td>3.500239e-01</td>\n",
       "      <td>39.506002</td>\n",
       "      <td>12.240918</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>2</td>\n",
       "      <td>-11977.564927</td>\n",
       "      <td>113.574510</td>\n",
       "      <td>50.430407</td>\n",
       "      <td>1.193885e-12</td>\n",
       "      <td>41.082523</td>\n",
       "      <td>13.799741</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>3</td>\n",
       "      <td>-12061.238900</td>\n",
       "      <td>119.857351</td>\n",
       "      <td>134.104381</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>38.566724</td>\n",
       "      <td>17.207161</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank           loo       p_loo       d_loo        weight         se  \\\n",
       "model3     0 -11927.134520  172.814712    0.000000  6.499761e-01  42.253480   \n",
       "model4     1 -11945.350051  106.596280   18.215531  3.500239e-01  39.506002   \n",
       "model1     2 -11977.564927  113.574510   50.430407  1.193885e-12  41.082523   \n",
       "model2     3 -12061.238900  119.857351  134.104381  0.000000e+00  38.566724   \n",
       "\n",
       "              dse  warning loo_scale  \n",
       "model3   0.000000    False       log  \n",
       "model4  12.240918     True       log  \n",
       "model1  13.799741    False       log  \n",
       "model2  17.207161     True       log  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = az.compare({'model1': trB, 'model2':trB_I, 'model3':trB_Is, 'model4': tr_hB}, ic='loo')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b706a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Log'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_compare(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76ce1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialNum</th>\n",
       "      <th>rectOri</th>\n",
       "      <th>rectValue</th>\n",
       "      <th>rating</th>\n",
       "      <th>RT</th>\n",
       "      <th>sub</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>moca_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.450375</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.366599</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.233494</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.850292</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000125</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trialNum  rectOri  rectValue  rating        RT  sub gender age  moca_score\n",
       "0         1       45          0       3  1.450375   14      F  26          30\n",
       "1         2        0          0       7  1.366599   14      F  26          30\n",
       "2         3       45          6       3  1.233494   14      F  26          30\n",
       "3         4       45          0       7  0.850292   14      F  26          30\n",
       "4         5        0          0       3  1.000125   14      F  26          30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0b51b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>sub</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>moca_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.238</td>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531</td>\n",
       "      <td>0.139</td>\n",
       "      <td>11</td>\n",
       "      <td>F</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.184</td>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457</td>\n",
       "      <td>0.318</td>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.259</td>\n",
       "      <td>0.094</td>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.356</td>\n",
       "      <td>0.280</td>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.155</td>\n",
       "      <td>0.163</td>\n",
       "      <td>17</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.135</td>\n",
       "      <td>0.227</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>83</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.355</td>\n",
       "      <td>0.293</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.264</td>\n",
       "      <td>0.307</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean     sd  sub gender age  moca_score\n",
       "0  0.339  0.238   10      M  18          28\n",
       "1  0.531  0.139   11      F  43          26\n",
       "2  0.100  0.184   13      F  48          28\n",
       "3  0.457  0.318   14      F  26          30\n",
       "4  0.259  0.094   15      F  58          26\n",
       "5  0.356  0.280   16      M  74          28\n",
       "6  0.155  0.163   17      M  59          29\n",
       "7  0.135  0.227   18      F  83          28\n",
       "8  0.355  0.293   19      M  32          28\n",
       "9  0.264  0.307   20      M  56          28"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = az.summary(trB_Is, var_names=['alpha'])[['mean','sd']]\n",
    "alpha['sub']=db['sub'].unique()\n",
    "alpha = alpha.merge(age, left_on='sub', right_on='sub')\n",
    "alpha['age'] = alpha['age'].astype('int')\n",
    "alpha.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df736d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Alpha')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.scatterplot(x='age',y='mean', data=alpha)\n",
    "plt.xlabel('Age', fontsize=16)\n",
    "plt.ylabel('Alpha', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43aef507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>r</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>p-val</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pearson</th>\n",
       "      <td>47</td>\n",
       "      <td>-0.098534</td>\n",
       "      <td>[-0.38, 0.19]</td>\n",
       "      <td>0.50994</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.101125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n         r          CI95%    p-val   BF10     power\n",
       "pearson  47 -0.098534  [-0.38, 0.19]  0.50994  0.224  0.101125"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.corr(alpha['age'], alpha['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "884a0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha.to_csv('data/alpha.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
