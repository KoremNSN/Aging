{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8c4f6",
   "metadata": {},
   "source": [
    "# Modeling Reversal Task\n",
    "\n",
    "### RW model of the reversal task in the aging experiment\n",
    "\n",
    "The aim of this notbook is to see if age affects appetative reversal learning.\n",
    "\n",
    "participants have 70 trials 40% reinforced.\n",
    "\n",
    "reversal of stimuli occurs after 35 trials.\n",
    "\n",
    "This notbook is based on Or's simulation of SCR.\n",
    "\n",
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c7023",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "make sure only participant with complete data set are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e15d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subject:  49\n"
     ]
    }
   ],
   "source": [
    "glober = '/media/Data/Lab_Projects/Aging/behavioral/Reversal/AG_*_RV/ETLearning_*.csv'\n",
    "\n",
    "db = pd.DataFrame()\n",
    "\n",
    "for sub in glob(glober):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(sub)\n",
    "        df['sub'] = sub.split('_')[2]\n",
    "        if df.shape[0] == 70:\n",
    "            \n",
    "            db = db.append(df[df.trialNum<36])\n",
    "    except:\n",
    "        print(sub)\n",
    "        print('error')\n",
    "\n",
    "#db['rating'] = db['rating'].replace(0, np.nan)\n",
    "print('number of subject: ', len(db['sub'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f026fe",
   "metadata": {},
   "source": [
    "## get descriptive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subj   = len(db['sub'].unique())\n",
    "n_trials = max(db.trialNum)\n",
    "\n",
    "trials, subj = np.meshgrid(range(n_trials), range(n_subj))\n",
    "trials = tt.as_tensor_variable(trials.T)\n",
    "subj   = tt.as_tensor_variable(subj.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de89482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim   = np.reshape([db['rectOri']],   (n_subj, n_trials)).T\n",
    "reward = np.reshape([db['rectValue']], (n_subj, n_trials)).T\n",
    "rating = np.reshape([db['rating']],    (n_subj, n_trials)).T\n",
    "\n",
    "stim   = np.array(stim/45,  dtype='int')\n",
    "reward = np.array(reward/6*9, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3681db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = tt.as_tensor_variable(stim)\n",
    "reward = tt.as_tensor_variable(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e65d1b",
   "metadata": {},
   "source": [
    "# create a pymc3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457ca1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# generate functions to run\n",
    "def update_Q(stim, reward,\n",
    "             Qs,vec,\n",
    "             alpha, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by theano.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the theano.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: tt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "     \n",
    "    PE = reward - Qs[tt.arange(n_subj), stim]\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * PE)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5319763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:15<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 197 seconds.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as mB:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057f4f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2598.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2097.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.026</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2509.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2939.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.168</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3672.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2090.0</td>\n",
       "      <td>1464.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2869.0</td>\n",
       "      <td>1915.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>2313.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3432.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.052  0.029   0.000    0.102      0.001    0.000    2777.0   \n",
       "alpha[1]   0.039  0.018   0.001    0.069      0.000    0.000    2050.0   \n",
       "alpha[2]   0.026  0.017   0.000    0.055      0.000    0.000    2583.0   \n",
       "alpha[3]   0.079  0.030   0.024    0.133      0.001    0.000    3015.0   \n",
       "alpha[4]   0.023  0.016   0.000    0.051      0.000    0.000    2598.0   \n",
       "alpha[5]   0.038  0.029   0.000    0.087      0.001    0.000    2097.0   \n",
       "alpha[6]   0.014  0.011   0.000    0.034      0.000    0.000    2840.0   \n",
       "alpha[7]   0.117  0.040   0.043    0.190      0.001    0.000    3182.0   \n",
       "alpha[8]   0.052  0.033   0.001    0.109      0.000    0.000    3450.0   \n",
       "alpha[9]   0.026  0.020   0.000    0.062      0.000    0.000    2509.0   \n",
       "alpha[10]  0.040  0.021   0.002    0.079      0.000    0.000    2939.0   \n",
       "alpha[11]  0.168  0.050   0.081    0.267      0.001    0.001    3672.0   \n",
       "alpha[12]  0.047  0.025   0.002    0.090      0.001    0.000    2090.0   \n",
       "alpha[13]  0.017  0.012   0.000    0.039      0.000    0.000    2869.0   \n",
       "alpha[14]  0.150  0.063   0.034    0.272      0.001    0.001    2261.0   \n",
       "alpha[15]  0.029  0.021   0.000    0.066      0.000    0.000    2652.0   \n",
       "alpha[16]  0.013  0.011   0.000    0.032      0.000    0.000    2477.0   \n",
       "alpha[17]  0.063  0.028   0.009    0.114      0.000    0.000    2989.0   \n",
       "alpha[18]  0.020  0.017   0.000    0.052      0.000    0.000    3432.0   \n",
       "alpha[19]  0.032  0.022   0.000    0.069      0.000    0.000    2776.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     1559.0    1.0  \n",
       "alpha[1]      910.0    1.0  \n",
       "alpha[2]     1387.0    1.0  \n",
       "alpha[3]     2009.0    1.0  \n",
       "alpha[4]     1993.0    1.0  \n",
       "alpha[5]     1444.0    1.0  \n",
       "alpha[6]     1814.0    1.0  \n",
       "alpha[7]     2321.0    1.0  \n",
       "alpha[8]     1878.0    1.0  \n",
       "alpha[9]     1725.0    1.0  \n",
       "alpha[10]    1950.0    1.0  \n",
       "alpha[11]    2480.0    1.0  \n",
       "alpha[12]    1464.0    1.0  \n",
       "alpha[13]    1915.0    1.0  \n",
       "alpha[14]    1221.0    1.0  \n",
       "alpha[15]    2313.0    1.0  \n",
       "alpha[16]    1969.0    1.0  \n",
       "alpha[17]    1854.0    1.0  \n",
       "alpha[18]    2148.0    1.0  \n",
       "alpha[19]    2253.0    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb238a8-005f-422d-bbca-54d7a147bb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 03:16<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 197 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_I:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_I = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f6865f-eff2-4d9b-8104-11f00f9d4fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.582</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4768.0</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.111</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.154</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.255</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4403.0</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.489</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.377</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3916.0</td>\n",
       "      <td>2837.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.414</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3676.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.487</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>2342.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>4434.0</td>\n",
       "      <td>2601.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2691.0</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.470</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3312.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.281</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3860.0</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3582.0</td>\n",
       "      <td>2637.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.448</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.410</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>3017.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.291</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3452.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.518</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>6217.0</td>\n",
       "      <td>2594.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3807.0</td>\n",
       "      <td>2334.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.582  0.262   0.123    1.000      0.004    0.003    4768.0   \n",
       "alpha[1]   0.111  0.083   0.000    0.232      0.002    0.002    3663.0   \n",
       "alpha[2]   0.154  0.104   0.000    0.332      0.002    0.001    3580.0   \n",
       "alpha[3]   0.255  0.104   0.067    0.451      0.002    0.001    4403.0   \n",
       "alpha[4]   0.115  0.088   0.000    0.273      0.001    0.001    3680.0   \n",
       "alpha[5]   0.489  0.226   0.085    0.924      0.004    0.003    3286.0   \n",
       "alpha[6]   0.377  0.297   0.000    0.891      0.005    0.004    3916.0   \n",
       "alpha[7]   0.414  0.151   0.143    0.705      0.003    0.002    3676.0   \n",
       "alpha[8]   0.487  0.285   0.005    0.932      0.004    0.003    5430.0   \n",
       "alpha[9]   0.469  0.283   0.000    0.923      0.004    0.003    4434.0   \n",
       "alpha[10]  0.294  0.234   0.000    0.794      0.005    0.004    2691.0   \n",
       "alpha[11]  0.470  0.206   0.128    0.904      0.004    0.003    3312.0   \n",
       "alpha[12]  0.281  0.159   0.025    0.571      0.003    0.002    3248.0   \n",
       "alpha[13]  0.054  0.045   0.000    0.132      0.001    0.001    3860.0   \n",
       "alpha[14]  0.412  0.302   0.000    0.915      0.005    0.004    3582.0   \n",
       "alpha[15]  0.448  0.226   0.028    0.851      0.004    0.003    3504.0   \n",
       "alpha[16]  0.410  0.313   0.001    0.916      0.007    0.005    1907.0   \n",
       "alpha[17]  0.291  0.149   0.057    0.583      0.003    0.002    3452.0   \n",
       "alpha[18]  0.518  0.282   0.083    0.999      0.003    0.003    6217.0   \n",
       "alpha[19]  0.361  0.272   0.001    0.869      0.005    0.004    3807.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     2391.0    1.0  \n",
       "alpha[1]     1934.0    1.0  \n",
       "alpha[2]     1938.0    1.0  \n",
       "alpha[3]     2060.0    1.0  \n",
       "alpha[4]     1699.0    1.0  \n",
       "alpha[5]     1919.0    1.0  \n",
       "alpha[6]     2837.0    1.0  \n",
       "alpha[7]     1943.0    1.0  \n",
       "alpha[8]     2342.0    1.0  \n",
       "alpha[9]     2601.0    1.0  \n",
       "alpha[10]    1825.0    1.0  \n",
       "alpha[11]    1845.0    1.0  \n",
       "alpha[12]    2340.0    1.0  \n",
       "alpha[13]    2095.0    1.0  \n",
       "alpha[14]    2637.0    1.0  \n",
       "alpha[15]    2223.0    1.0  \n",
       "alpha[16]    3017.0    1.0  \n",
       "alpha[17]    2230.0    1.0  \n",
       "alpha[18]    2594.0    1.0  \n",
       "alpha[19]    2334.0    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_I, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125ae433-0091-4b97-ba95-b489803d1841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/arviz/stats/stats.py:694: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>0</td>\n",
       "      <td>-4101.342000</td>\n",
       "      <td>81.081250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862673</td>\n",
       "      <td>25.667963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>1</td>\n",
       "      <td>-4142.566014</td>\n",
       "      <td>74.514335</td>\n",
       "      <td>41.224014</td>\n",
       "      <td>0.137327</td>\n",
       "      <td>22.974535</td>\n",
       "      <td>10.713163</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo      p_loo      d_loo    weight         se  \\\n",
       "model1     0 -4101.342000  81.081250   0.000000  0.862673  25.667963   \n",
       "model2     1 -4142.566014  74.514335  41.224014  0.137327  22.974535   \n",
       "\n",
       "              dse  warning loo_scale  \n",
       "model1   0.000000     True       log  \n",
       "model2  10.713163    False       log  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bbfd10-7229-4a13-b3a6-473e50cee83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 10 jobs)\n",
      "NUTS: [eps, beta, alpha, intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 14:57<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 899 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as mB_Is:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    trB_Is = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4143cb4-6339-4b21-955b-f11e20689065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.343</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2591.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.271</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.165</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.284</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2986.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.338</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.276</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.289</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1698.0</td>\n",
       "      <td>2085.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.383</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[10]</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2733.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[11]</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[12]</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[13]</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[14]</th>\n",
       "      <td>0.208</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2819.0</td>\n",
       "      <td>1769.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[15]</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[16]</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[17]</th>\n",
       "      <td>0.251</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2915.0</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[18]</th>\n",
       "      <td>0.395</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[19]</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]   0.343  0.324   0.000    0.907      0.007    0.005    2039.0   \n",
       "alpha[1]   0.144  0.210   0.000    0.629      0.004    0.003    2591.0   \n",
       "alpha[2]   0.271  0.242   0.000    0.744      0.004    0.003    2157.0   \n",
       "alpha[3]   0.165  0.116   0.009    0.369      0.002    0.001    3401.0   \n",
       "alpha[4]   0.284  0.266   0.000    0.808      0.005    0.004    1565.0   \n",
       "alpha[5]   0.404  0.239   0.000    0.814      0.004    0.003    2986.0   \n",
       "alpha[6]   0.338  0.284   0.000    0.874      0.005    0.004    2056.0   \n",
       "alpha[7]   0.276  0.142   0.040    0.528      0.002    0.002    3666.0   \n",
       "alpha[8]   0.289  0.278   0.000    0.848      0.005    0.004    1698.0   \n",
       "alpha[9]   0.383  0.294   0.000    0.889      0.007    0.005    1535.0   \n",
       "alpha[10]  0.238  0.259   0.000    0.802      0.004    0.003    2733.0   \n",
       "alpha[11]  0.199  0.099   0.040    0.375      0.001    0.001    3750.0   \n",
       "alpha[12]  0.243  0.218   0.000    0.668      0.004    0.003    2206.0   \n",
       "alpha[13]  0.307  0.289   0.000    0.858      0.006    0.004    1992.0   \n",
       "alpha[14]  0.208  0.147   0.002    0.466      0.003    0.002    2819.0   \n",
       "alpha[15]  0.525  0.263   0.000    0.922      0.006    0.004    1808.0   \n",
       "alpha[16]  0.407  0.219   0.000    0.816      0.004    0.003    2604.0   \n",
       "alpha[17]  0.251  0.203   0.000    0.647      0.003    0.002    2915.0   \n",
       "alpha[18]  0.395  0.304   0.000    0.904      0.007    0.005    1516.0   \n",
       "alpha[19]  0.315  0.288   0.000    0.867      0.005    0.004    2057.0   \n",
       "\n",
       "           ess_tail  r_hat  \n",
       "alpha[0]     2544.0    1.0  \n",
       "alpha[1]     1777.0    1.0  \n",
       "alpha[2]     2145.0    1.0  \n",
       "alpha[3]     2059.0    1.0  \n",
       "alpha[4]     1929.0    1.0  \n",
       "alpha[5]     1579.0    1.0  \n",
       "alpha[6]     1434.0    1.0  \n",
       "alpha[7]     1932.0    1.0  \n",
       "alpha[8]     2085.0    1.0  \n",
       "alpha[9]     1608.0    1.0  \n",
       "alpha[10]    2064.0    1.0  \n",
       "alpha[11]    2160.0    1.0  \n",
       "alpha[12]    1890.0    1.0  \n",
       "alpha[13]    1819.0    1.0  \n",
       "alpha[14]    1769.0    1.0  \n",
       "alpha[15]     676.0    1.0  \n",
       "alpha[16]    1001.0    1.0  \n",
       "alpha[17]    2033.0    1.0  \n",
       "alpha[18]    1064.0    1.0  \n",
       "alpha[19]    2208.0    1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trB_Is, var_names='alpha')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a2e330-0b72-4599-8578-e228d3dfa5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/arviz/stats/stats.py:694: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>0</td>\n",
       "      <td>-4098.001929</td>\n",
       "      <td>106.029952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.897614e-01</td>\n",
       "      <td>25.380207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4101.342000</td>\n",
       "      <td>81.081250</td>\n",
       "      <td>3.340071</td>\n",
       "      <td>4.102386e-01</td>\n",
       "      <td>25.667963</td>\n",
       "      <td>6.829368</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>2</td>\n",
       "      <td>-4142.566014</td>\n",
       "      <td>74.514335</td>\n",
       "      <td>44.564086</td>\n",
       "      <td>9.992007e-16</td>\n",
       "      <td>22.974535</td>\n",
       "      <td>9.116228</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo       p_loo      d_loo        weight         se  \\\n",
       "model3     0 -4098.001929  106.029952   0.000000  5.897614e-01  25.380207   \n",
       "model1     1 -4101.342000   81.081250   3.340071  4.102386e-01  25.667963   \n",
       "model2     2 -4142.566014   74.514335  44.564086  9.992007e-16  22.974535   \n",
       "\n",
       "             dse  warning loo_scale  \n",
       "model3  0.000000    False       log  \n",
       "model1  6.829368     True       log  \n",
       "model2  9.116228    False       log  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.compare({'model1': trB, 'model2':trB_I, 'model3':trB_Is})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddbe8f",
   "metadata": {},
   "source": [
    "## hierarchal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd609241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 8 jobs)\n",
      "NUTS: [eps, beta, beta_sd, beta_h, alpha, kappa_log, phi, intercept_matt, sd, mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 32:24<00:00 Sampling 4 chains, 473 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1946 seconds.\n",
      "There were 23 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9612888080508708, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "There were 198 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.8168502366291275, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "There were 135 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 117 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as m_H:\n",
    "    \n",
    "    # intercept\n",
    "    mu = pm.Normal('mu', 0, 1)\n",
    "    sd = pm.HalfNormal('sd',5) \n",
    "    intercept_matt = pm.Normal('intercept_matt', mu=0, sd=1, shape=n_subj)\n",
    "    intercept = pm.Deterministic('intercept',intercept_matt + mu*sd)\n",
    "    \n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0)\n",
    "\n",
    "    kappa_log = pm.Exponential(\"kappa_log\", lam=1.5)\n",
    "    kappa = pm.Deterministic(\"kappa\", tt.exp(kappa_log))\n",
    "\n",
    "    alpha = pm.Beta(\"alpha\", alpha=phi * kappa, beta=(1.0 - phi) * kappa, shape=n_subj)\n",
    "    \n",
    "    \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 1)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "       \n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec0 = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec0],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "     \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_hB = pm.sample(target_accept=.9, chains=4, cores=8, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3c60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha[0]</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>579.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[1]</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>970.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[2]</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>522.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[3]</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>578.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[4]</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>681.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[5]</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>570.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[6]</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[7]</th>\n",
       "      <td>0.157</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>328.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[8]</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>867.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha[9]</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>722.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "alpha[0]  0.048  0.034   0.000    0.108      0.001    0.001     579.0   \n",
       "alpha[1]  0.032  0.026   0.000    0.077      0.001    0.000     970.0   \n",
       "alpha[2]  0.024  0.029   0.000    0.073      0.001    0.001     522.0   \n",
       "alpha[3]  0.092  0.060   0.000    0.195      0.002    0.002     578.0   \n",
       "alpha[4]  0.017  0.023   0.000    0.056      0.001    0.001     681.0   \n",
       "alpha[5]  0.047  0.065   0.000    0.166      0.002    0.002     570.0   \n",
       "alpha[6]  0.010  0.016   0.000    0.032      0.000    0.000     637.0   \n",
       "alpha[7]  0.157  0.087   0.014    0.317      0.004    0.003     328.0   \n",
       "alpha[8]  0.047  0.044   0.000    0.121      0.002    0.002     867.0   \n",
       "alpha[9]  0.020  0.023   0.000    0.063      0.001    0.000     722.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "alpha[0]     561.0   1.01  \n",
       "alpha[1]     611.0   1.00  \n",
       "alpha[2]     544.0   1.01  \n",
       "alpha[3]     925.0   1.01  \n",
       "alpha[4]     900.0   1.00  \n",
       "alpha[5]     540.0   1.01  \n",
       "alpha[6]    1001.0   1.00  \n",
       "alpha[7]     993.0   1.02  \n",
       "alpha[8]     874.0   1.01  \n",
       "alpha[9]     837.0   1.01  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(tr_hB, var_names='alpha')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b224f3",
   "metadata": {},
   "source": [
    "## model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18dd6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nachshon/anaconda3/envs/reversal/lib/python3.9/site-packages/arviz/stats/stats.py:694: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>d_loo</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>loo_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>0</td>\n",
       "      <td>-4085.274658</td>\n",
       "      <td>66.166883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>23.379180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4101.342000</td>\n",
       "      <td>81.081250</td>\n",
       "      <td>16.067343</td>\n",
       "      <td>6.554757e-13</td>\n",
       "      <td>25.667963</td>\n",
       "      <td>5.445579</td>\n",
       "      <td>True</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rank          loo      p_loo      d_loo        weight         se  \\\n",
       "model2     0 -4085.274658  66.166883   0.000000  1.000000e+00  23.379180   \n",
       "model1     1 -4101.342000  81.081250  16.067343  6.554757e-13  25.667963   \n",
       "\n",
       "             dse  warning loo_scale  \n",
       "model2  0.000000    False       log  \n",
       "model1  5.445579     True       log  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp = az.compare({'model1':trB, 'model2': tr_hB}, ic='loo')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b706a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Log'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAACaCAYAAABc6LQ8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR1klEQVR4nO3df3Ac9XnH8fdzd5qI0EBpTWZ8xq5D3FjFwZCOQpNgMG08MWkbYjolOCQw1HbtSSIVT+IGGDmcpWDyB3FIOgSDR1YC7mBmSImZMBNTnGJj3EKQjPwD2zQmCa1kpWkyscyP2tHdPf3jVuQstLJ0d9JqV5/XzI5Xu3e7z+O922e/+93bNXdHRERkOKmoAxARkclLRUJEREKpSIiISCgVCRERCaUiISIioVQkREQkVCbqAGpp2rRpPnv27KjDkEnktdde413velfUYYhMal1dXb9y9/OHm5eoIjF79mw6OzujDkMmiXw+z/r162lpaSGTSdRHXaSmzOzVsHk63SSJZWbMnTsXM4s6FJHY0uGVJFY6nWbp0qVRhyESa2pJSGIVCgUef/xxCoVC1KGIxJaKhCSWu9Pd3Y3uTyZSORUJEREJpSIhIiKhVCQksVKpFNdffz2plD7mIpXS1U2SWKlUioaGhqjDEIk1HWJJYuXzedra2sjn81GHIhJbKhKSaLqySaQ6KhIiIhJKRUISrb6+PuoQRGJNHdeSWJlMhltvvTXqMERiTS0JSaxisci+ffsoFotRhyISWyoSkljFYpFt27apSIhUQUVCRERCqUiIiEgoFQlJLDPjQx/6kB46JFIFXd0kiZVOp1m8eHHUYYjEmloSkliFQoEHH3xQDx0SqYKKhCSWu/Pzn/9ct+YQqcKEFgkzO36G+bPNrDsYX2Jm+8xsv5ntMbOLJyJGSRa1ImSqGK8bWU7mlkQv8FF3nw/kgPsjjkdipKOjg4aGBr761a/S0NBAR0dH1CGJjIv29nay2Sx1dXVks1na29truvwzdlyb2WzgCeA54MPAXmALsA6YBtwA/BT4DvAe4ASw3N1fNrPzga3AecCuIcv9MnAd8A7g++6eK5/v7i+U/bkXuGDM2cmU1NHRQS6X4/7776ehoYEjR46watUqAJYtWxZxdCK1097eTnNzMydPngSgr6+P5uZmAFasWFGTddiZztcGReInwCXAEaAL6HL3FWZ2LfBZSkf9v3D3u8zsGuBL7r7QzO4FXnX3u81sKbDV3c3MPgYsAb5AqTXzA+AuoAfY5u6XDolhDTDX3f9+pFgbGxu9s7NzTP8BSZXP56fscxTmzZvHhg0bWLx4MSdOnOCcc87hySefZM2aNRw8eDDq8CKRyWTIZHQxY9Jks1n6+vqGnd7b2zvq5ZhZl7s3DjvT3UccgNnA4bK/HwKuD8YvpFQ0XgRmlb3ml0Aa6AZmBtPSwEAw/nXgZ8H8buAocHOwru4h678COAz8YUh8K4FOoHPWrFkuJblczoEpPWQyGV+3bp1nMpnIY4l6yOVyUX8kpcYGBgZG3OYDAwOjXhbQ6SE1YLSHFqfKxotlfxcp7fyHGu7XSz5k/p3uvvm0N5VaLeV/vw/oAK5x918PF5i7bwI2QaklEZ7C1LJ27Vpuu+22qMOIxGBLYtGiRWzYsIHf/OY37NixY8q3JCRZMpkM06dPD21J1Gqb1+qTswu4EVgfnG465O4FM9sNLAXuBj5Vtr7tQKuZPeLub5jZBcDJ8gWa2buBbZT6Nw7XKM4pYyqfXmhpaaGpqYmNGzdy6tQpnn76aZqammhra9PzJSRR2traTuuTgNIzVFpbW2u2jlrtRVqB75rZfuA1YHkwvQ14JOiP+CHQD+DuT5nZRcBzwS0TXgc+PWSZXwZmAP8UvCbvYefMRMoMdk5/8Ytf5OjRo8yZM4e2tjZ1WkviDHZO53I5jh07RjabpbW1tWad1jCKjus4Uce1DJXP56dsi0qmlmo+6yN1XE/m30mIVKVQKLB79279oE6mhPE6GFKRkMRyd5555hndlkOkCioSIiISSkVCRERCqUhIYqVSKT7+8Y+TSuljLlIpXfYhiZVKpbjsssuiDkMk1nSIJYmVz+e55557puw9rERqQUVCEu3EiRNRhyASayoSIiISSkVCRERCqUhIYqXTaW6//XbS6eFuVCwio6EiIYnl7vT09OgX1yJVUJGQxCoWi2zZsoVisRh1KCKxpSIhIiKhVCRERCSUioQklplx0UUXETy0SkQqoNtySGKl02muu+66qMMQiTW1JCSxCoUCjz32mB46JFIFFQlJLHfnwIEDugRWpAoqEiIiEkpFQkREQqlISGKlUiluuOEGPXRIpAr69khimRkXXnihLoEVqYKKhCRWoVDgzjvv1NVNIlVQkRARkVAqEiIiEkpFQhLt7LPPjjoEkVjTbTkksTKZDGvWrIk6DJFYU0tCEqtYLNLV1aXnSYhUQUVCEqtYLPLEE0+oSIhUQUVCRERCqUiIiEgoFQlJLDPj8ssv1y+uRaqgIiGjcvz4cTZv3kx/f3/UoYxaOp1m0aJFpNPpqEMRiS0VCRmVXbt20dPTw86dO6MOZdTy+TybN28mn89HHYpIbOl3ElNIsVis6Eqf/v5+9u/fD8D+/ftZsGAB55577piWkUqlIrkba09Pz4SvUyRJYl8kzGwlsBJg1qxZEUczuT3zzDPs2rWrqmUUi0XuvffeMb9v4cKFXHXVVVWtW0QmXuyLhLtvAjYBNDY26jmVI7jyyitZsGDBmN7T39/Pfffdd1oLJJVK8fnPf35MrQk900EknmJfJGT0Kjnl8+yzz4ZO/+QnP1mLsMZNOp2mqalJHdciVdDhnYyot7f3bf0YxWKR3t7eiCIaG3c1LkWqoZaEjGjVqlXD7mjj8NuDQqHAt7/9bVpaWshk9FEXqYS+OTIinaoRmdp0uklEREKpSEiizZw5M+oQRGJNp5sksTKZDMuWLYs6DJFYU0tCEqtQKLBjxw4KhULUoYjE1oQWCTM7fob5s82sOxg/z8yeNrPXzeybExCenEHc7oHk7uzZs0eXwUpiTcR3cjK3JE4BdwD/GHUgU11HRwdz5syhrq6OOXPm0NHREXVIIlNae3s72WyWuro6stks7e3t47auM/ZJmNls4AngOeDDwF5gC7AOmAbcAPwU+A7wHuAEsNzdXzaz84GtwHnAriHL/TJwHfAO4Pvuniuf7+5vArvN7L2VpyfV6ujoIJfL8cADD3DFFVewe/duVq5cCaDz/SIRaG9vp7m5mZMnTwLQ19dHc3MzACtWrKj5+uxMTfGgSPwEuAQ4AnQBXe6+wsyuBT4L9AK/cPe7zOwa4EvuvtDM7gVedfe7zWwpsNXdzcw+BiwBvkCpNfMD4C6gB9jm7peWrf9m4FJ3X32mZBobG72zs3MM6f9OPp+P3emUiTBv3jw2bNjA1Vdf/da07du3s2bNGg4ePBhhZGdWLBY5cOAAF1988YTcOyqTyehHezLustksfX19w06v9E4IZtbl7o3DznT3EQdgNnC47O+HgOuD8QspFY0XgVllr/klkAa6gZnBtDQwEIx/HfhZML8bOArcHKyre8j6bwa+OUJ8K4FOoHPWrFleqVwu54AGDRUPuVyu4s+fyGgMDAyM+BkcGBioaLlAp4fsY0d72HOqbLxY9neR0s5/qOHu2eBD5t/p7ptPe1Op1TImXqO7wK5du5bbbrut0rcnVpxbEvl8no0bN/K5z31uQo7w1YqQ8ZbJZJg+fXpoS2I8PoO1WuIu4EZgfXC66ZC7F8xsN7AUuBv4VNn6tgOtZvaIu79hZhcAJ2sUS0V0qmB4LS0tNDU1sWnTprf6JJqammhra6O+vj7q8EaUz+d58803qa+v17aVxGhrazutTwKgvr6e1tbWcVlfrb45rcB3zWw/8BqwPJjeBjwS9Ef8EOgHcPenzOwi4LngRnGvA58eulAzOwr8AVBnZn8LLHT3V2oUs4zCYOf0LbfcwtGjR5kzZw5tbW3qtBaJyGDndC6X49ixY2SzWVpbW8el0xpG0XEdJ9V0XMuZ5fP5WB2R5/N51q9fr7vASmLV6js5Use1vjkyanHb0abTab7yla/E4rbmIpWYiO/kZP4xnUhV3J1XXnlFv7gWqYKKhCRWsVjk4YcfftuT9URk9FQkREQklIqEiIiEUpGQxDIz5s+fr45rkSrE63IVkTFIp9Nce+21UYchEmtqSUhiFQoFHn30UT10SKQKKhKSWO7OoUOHdAmsSBVUJEREJJSKhIiIhFKRkMRKpVLcdNNNE/LAIZGk0rdHEsvMmDFjhi6BFamCioQkVqFQ4Gtf+5qubhKpgoqEiIiEUpEQEZFQKhKSaOeee27UIYjEmm7LIYmVyWRYvXp11GGIxJpaEpJYxWKR559/Xs+TEKmCioQkVrFYZPv27SoSIlVQkRARkVAqEiIiEsqSdIdMM/tf4NWo4whMA34VdRDjLOk5Kr/4S3qOtcrvj9z9/OFmJKpITCZm1unujVHHMZ6SnqPyi7+k5zgR+el0k4iIhFKREBGRUCoS42dT1AFMgKTnqPziL+k5jnt+6pMQEZFQakmIiEgoFYkqmdk3zOx42d+Xm1mXmeXNbEnZ9CVmts/M9pvZHjO7uGzeX5rZy2Z21MyaJzaDkY02v2De2iCHw2Z2Rdn0OOVXb2bfC2J91symB9MzZvZQsP0OmVlT2XsmbX4w+hyDeR8ws+fN7CUze7Fs+qTNcSz5BfNnmNkJM1tdNm3S5gdj+pzWfj/j7hoqHID5wBbgeNm0WcAlwEPAkrLpHwSmBeOLgD3BeAY4CswE3gkcBi6IOrcK8rsYeAGoAxqAl2KaXzPwzWB8OfBAMP4pYGswfg7wP8G/kza/CnLMAAeA9wd/vztJ27Bs/sPA94DVkz2/CrZhzfczaklUyErPxLwbuL18urv/l7vvA4pDpr/g7oM/etkLXBCMXwYcdvf/dvc3gceAT4xr8KMw1vwoxfyIuw+4+xHguJn9CTHLj1JsW4LxrcBfDb4FeKeZpSl9yV4HTjFJ84OKclwMdLn7QQB3/2UwfVLmWEF+mNnHKBX4g2Wvn5T5wdhzHI/9jIpE5ZYBT7t7T4Xv/ddgPAv0ls3rAWZUGVstjDW/sDzilt9b8QZfprSZ1VH6Uv0f0EfpiKzF3U8xefODsef4x0DKzJ4ys71lp2Mma45jys/M3gHcAawLe31gsuQHY9+GQ99b9X5Gz5MYgZn9O6VTCkMtD4arKljmFcF7FwxOGuZlE3LJWY3zC8sjbvkNjXfw7w8Cv6X0ZTsf2Glm/zbM62GC8oOa55gBPgL8GaVcd5nZfwzzeojnNrwV2Ozu/aUD9NDXQ3y34eAya7afUZEYgbt/ZLjpZrYAeC/wn8GH7Rwze9nd5460PDN7H9ABXOPuvw4m93J6RZ/B6RV/3NQ4v+HyOEbp6DtO+Q3m8QszOwvIu/uAmX0G+KG754E+M+sGLiXC7Qc1z7EH2Dn42TSzpyidD3+JZGzDy4DlZpYDfh8omtkpYB8J2YbB+2q7n4m6UyYJA2UdSmXTvsvpHbvvBg4BVw553WCH0gXAWcFrZkadUwX5zQd+HOTzPt7ecR2L/IB/AO4JxpcBm4LxW/ld5+A5QU7viUN+Y8jxPEoXH5xF6QKEZ4HL45DjaPIb8vp1vL3jetLmN4ZtWPP9TOSJJ2EYsvE+QOl83xuU7s64N5j+daAf6A6GzrL3fAJ4OdiIt0SdTyX5BfNyQQ6HgYUxze8sSv0PPwH2ANlg+u9RuiLmIKUj6y/EJb/R5hjMuzHYgRwE7ohLjqPNr+w1bxWJOOQ32hzHYz+jX1yLiEgoXd0kIiKhVCRERCSUioSIiIRSkRARkVAqEiIiEkpFQqQGzEyXCUoiqUiIiEgoFQmRcWRmd5jZwWD4lpllgukzzWxnMH2rmT1nZldFG63I26lIiIwTM/tr4BpKt2m+BLgQWBnM/hbwL+7+fkq/kv1gJEGKnIGKhMj4+Qvgn939TXcvAJuBjwbz/hx4EMDdu4D90YQoMjIVCZHxY0zgLadFxoOKhMj4+RHwGTM7K3ii3d8F0wB2UrqZHmb2AUqPfxWZdPQ8CZEaCZ7HMOjH7v43ZvanQCelFsWPgE3B/NXAFjNbDrxI6ZkG/RMYrsio6C6wIhEIHhTzW3cvmFkDsAOY6+5vRByayGnUkhCJxjyg3X73HM2VKhAyGaklISIiodRxLSIioVQkREQklIqEiIiEUpEQEZFQKhIiIhJKRUJEREL9P5k1i1qwssOTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "az.plot_compare(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a52b65",
   "metadata": {},
   "source": [
    "## Correlate expected value and subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44411662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 49)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = trB.posterior.stack(draws=('chain','draw'))\n",
    "a = a.expected_value\n",
    "mean_a = np.mean(a, axis=2)\n",
    "mean_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "400bdd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.27892827168710455, 0.1046705904167483)\n",
      "(0.3780308551516219, 0.0251521131189318)\n",
      "(0.146632848682171, 0.40060357184691947)\n",
      "(0.5043119470447103, 0.0020075948139449185)\n",
      "(0.103949771127254, 0.5523419431558565)\n",
      "(0.09714864186687253, 0.5787700805757358)\n",
      "(-0.19253298712026426, 0.26782704952544334)\n",
      "(0.3829978955931457, 0.023151390120439947)\n",
      "(0.3697169110796787, 0.02881916008784062)\n",
      "(0.014020547755306584, 0.936286498769684)\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    cor1 = scipy.stats.pearsonr(rating[:,i], mean_a[:,i])\n",
    "    print(cor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc336ba9",
   "metadata": {},
   "source": [
    "## The Pearce-Hall Hybrid model\n",
    "\n",
    "This is Or's attempt to build the PH Hybrid model. This model doesn't assume a simple constant learning rate (as the RW), rather, it incorporated both a constant learning rate and a dynamic one. The dynamic one is being updated by the amount of new information given. The model goes like that: \n",
    "\n",
    "(1) Vi(k+1) = Vi (k) + (k) + (k)\n",
    "\n",
    "(2)  = shock - Vi(k) \n",
    "\n",
    "(3) (k+1) = || + (1-)(k)\n",
    "\n",
    "So the current value is an update of the previous one plus a constant learning rate (kappa) and an associability weight (alpha) (times the delta = prediction error).\n",
    "\n",
    "The  is set by a constant weight of associability (eta) and the previous .\n",
    "\n",
    "So now, our updating function will include those elements as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7fde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate functions to run\n",
    "def update_Q_hb(stim, shock,\n",
    "             Qs,vec,alpha,assoc,\n",
    "             eta,kappa, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to Hybrid PH model\n",
    "    For information, please see this paper: https://www.sciencedirect.com/science/article/pii/S0896627316305840?via%3Dihub\n",
    "  \n",
    "    \"\"\"\n",
    "      \n",
    "    delta = shock - Qs[tt.arange(n_subj), stim]\n",
    "    alpha = tt.set_subtensor(alpha[tt.arange(n_subj), stim], eta * abs(delta) + (1-eta)*alpha[tt.arange(n_subj), stim])\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + kappa*alpha[tt.arange(n_subj), stim] * delta)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    # we use the same idea to get the associability per trial\n",
    "    assoc = tt.set_subtensor(assoc[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                alpha[tt.arange(n_subj),1], alpha[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec, alpha, assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae9b4457",
   "metadata": {},
   "outputs": [
    {
     "ename": "SamplingError",
     "evalue": "Initial evaluation of model at starting point failed!\nStarting values:\n{'phi_interval__': array([0., 0.]), 'intercept': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log1_log__': array(-0.77197803), 'kappa_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'beta_h': array(0.), 'beta_sd_log__': array(1.38364656), 'beta': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log2_log__': array(-0.77197803), '_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'eps_log__': array(1.38364656)}\n\nInitial evaluation results:\nphi_interval__      -2.77\nintercept         -123.89\nk_log1_log__        -1.06\nkappa_logodds__    -75.01\nbeta_h              -0.92\nbeta_sd_log__       -0.77\nbeta              -112.83\nk_log2_log__        -1.06\n_logodds__        -75.01\neps_log__           -0.77\nscrs                  NaN\nName: Log-probability of test_point, dtype: float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSamplingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22753/3985315658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m#assoc = pm.Deterministic('alpha', assoc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_accept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inferencedata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/sampling.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mcheck_start_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/reversal/lib/python3.9/site-packages/pymc3/util.py\u001b[0m in \u001b[0;36mcheck_start_vals\u001b[0;34m(start, model)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             raise SamplingError(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;34m\"Initial evaluation of model at starting point failed!\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;34m\"Starting values:\\n{}\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSamplingError\u001b[0m: Initial evaluation of model at starting point failed!\nStarting values:\n{'phi_interval__': array([0., 0.]), 'intercept': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log1_log__': array(-0.77197803), 'kappa_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'beta_h': array(0.), 'beta_sd_log__': array(1.38364656), 'beta': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'k_log2_log__': array(-0.77197803), '_logodds__': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'eps_log__': array(1.38364656)}\n\nInitial evaluation results:\nphi_interval__      -2.77\nintercept         -123.89\nk_log1_log__        -1.06\nkappa_logodds__    -75.01\nbeta_h              -0.92\nbeta_sd_log__       -0.77\nbeta              -112.83\nk_log2_log__        -1.06\n_logodds__        -75.01\neps_log__           -0.77\nscrs                  NaN\nName: Log-probability of test_point, dtype: float64"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "  \n",
    "    # hyperpriors for eta and kappa\n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0, shape=2)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    #    \n",
    "    k_log1 = pm.Exponential(\"k_log1\", lam=1.5)\n",
    "    k1 = pm.Deterministic(\"k1\", tt.exp(k_log1))\n",
    "    kappa = pm.Beta(\"kappa\", alpha=phi[0] * k1, beta=(1.0 - phi[0]) * k1, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 5)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "    \n",
    "    # \n",
    "    k_log2 = pm.Exponential(\"k_log2\", lam=1.5)\n",
    "    k2 = pm.Deterministic(\"k2\", tt.exp(k_log2))\n",
    "    eta = pm.Beta('', alpha=phi[1] * k2, beta=(1.0 - phi[1]) * k2, shape=n_subj)\n",
    "    \n",
    "   # kappa = pm.Beta('kappa', 1,1, shape=n_subj)\n",
    "   # eta = pm.Beta('eta', 1,1, shape=n_subj)\n",
    "    \n",
    "  #  beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = 4.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 4.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    alpha = 0 * tt.ones((n_subj,2), dtype='float64')\n",
    "    assoc = 0 * tt.ones((n_subj,1), dtype='float64')\n",
    "    \n",
    "    [Qs,vec, alpha, assoc], updates = theano.scan(\n",
    "        fn=update_Q_hb,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec, alpha, assoc],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    scrs = pm.Normal('scrs', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    # add associabillity\n",
    "    #assoc = pm.Deterministic('alpha', assoc)\n",
    "    \n",
    "    tr = pm.sample(target_accept=.9, chains=4, cores=10, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f33f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(tr, var_names='')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ce1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
