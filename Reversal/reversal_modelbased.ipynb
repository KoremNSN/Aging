{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8c4f6",
   "metadata": {},
   "source": [
    "# Modeling Reversal Task\n",
    "\n",
    "### RW model of the reversal task in the aging experiment\n",
    "\n",
    "The aim of this notebook is to see if age affects appetative reversal learning.\n",
    "\n",
    "participants have 70 trials 40% reinforced.\n",
    "\n",
    "reversal of stimuli occurs after 35 trials.\n",
    "\n",
    "This notebook is based on Or's simulation of SCR.\n",
    "\n",
    "Rescorla-Wagner model will follow the formula:\n",
    "\n",
    "$$\n",
    "V(n+1) = V(n) - α*PE\n",
    "$$\n",
    "$$\n",
    "PE = V(n)-outcome\n",
    "$$\n",
    "\n",
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809a0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c7023",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "make sure only participant with complete data set are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d96f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = pd.read_csv('../demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e15d976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of subject:  95\n"
     ]
    }
   ],
   "source": [
    "glober = '/media/Data/Lab_Projects/Aging/behavioral/Reversal/AG_*_RV/ETLearning_*.csv'\n",
    "\n",
    "db = pd.DataFrame()\n",
    "\n",
    "for sub in glob(glober):\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(sub)\n",
    "        df['sub'] = sub.split('_')[2]\n",
    "        if df.shape[0] == 70:\n",
    "            db = pd.concat([db, df], axis = 0)\n",
    "            #db = db.append(df)#[df.trialNum<36])\n",
    "    except:\n",
    "        print(sub)\n",
    "        print('error')\n",
    "\n",
    "#db['rating'] = db['rating'].replace(0, np.nan)\n",
    "db = db.sort_values(by=['sub','trialNum'])\n",
    "print('number of subject: ', len(db['sub'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d8b681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid subjects:  68\n"
     ]
    }
   ],
   "source": [
    "db['sub'] = db['sub'].astype('int')\n",
    "db = db.merge(age, left_on='sub', right_on='sub')\n",
    "db = db.sort_values('sub')\n",
    "print('Valid subjects: ', len(np.unique(db['sub'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7722f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sub  rating\n",
      "0  102      13\n"
     ]
    }
   ],
   "source": [
    "x = db[db['RT']==-1].groupby('sub').count()['rating']\n",
    "x = x[x>5].reset_index()\n",
    "print(x)\n",
    "db = db[~db['sub'].isin(x['sub'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a86177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>moca_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>F</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>F</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>F</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sub gender  age  moca_score\n",
       "0   10      M   18          28\n",
       "1   11      F   43          26\n",
       "2   13      F   48          28\n",
       "3   14      F   26          30\n",
       "4   15      F   58          26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = db.drop_duplicates('sub')\n",
    "subs = subs.drop(['trialNum', 'rectOri', 'rectValue', 'rating', 'RT'],axis = 1).reset_index(drop=True)\n",
    "subs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f026fe",
   "metadata": {},
   "source": [
    "## get descriptive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d26b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subj   = len(db['sub'].unique())\n",
    "n_trials = max(db.trialNum)\n",
    "\n",
    "trials, subj = np.meshgrid(range(n_trials), range(n_subj))\n",
    "trials = tt.as_tensor_variable(trials.T)\n",
    "subj   = tt.as_tensor_variable(subj.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de89482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim   = np.reshape([db['rectOri']],   (n_subj, n_trials)).T\n",
    "reward = np.reshape([db['rectValue']], (n_subj, n_trials)).T\n",
    "rating = np.reshape([db['rating']],    (n_subj, n_trials)).T\n",
    "\n",
    "stim   = np.array(stim/45,  dtype='int')\n",
    "reward = np.array(reward/6, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3681db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = tt.as_tensor_variable(stim)\n",
    "reward = tt.as_tensor_variable(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b655ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = [np.nan if 0 else x/9 for x in rating]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e65d1b",
   "metadata": {},
   "source": [
    "# create a pymc3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457ca1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate functions to run\n",
    "def update_Q(stim, reward,\n",
    "             Qs,vec,\n",
    "             alpha, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to the RL update rule.\n",
    "    It will be called by theano.scan to do so recursevely, given the observed data and the alpha parameter\n",
    "    This could have been replaced be the following lamba expression in the theano.scan fn argument:\n",
    "        fn=lamba action, reward, Qs, alpha: tt.set_subtensor(Qs[action], Qs[action] + alpha * (reward - Qs[action]))\n",
    "    \"\"\"\n",
    "     \n",
    "    PE = reward - Qs[tt.arange(n_subj), stim]\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * PE)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6086e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate functions to run\n",
    "def update_Q_hall(stim, reward,\n",
    "             Qs,vec,alpha,assoc,\n",
    "             eta,kappa, n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to Hybrid PH model\n",
    "    For information, please see this paper: https://www.sciencedirect.com/science/article/pii/S0896627316305840?via%3Dihub\n",
    "  \n",
    "    \"\"\"\n",
    "      \n",
    "    delta = reward - Qs[tt.arange(n_subj), stim]\n",
    "    alpha = tt.set_subtensor(alpha[tt.arange(n_subj), stim], eta * abs(delta) + (1-eta)*alpha[tt.arange(n_subj), stim])\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + kappa*alpha[tt.arange(n_subj), stim] * delta)\n",
    "    \n",
    "    # in order to get a vector of expected outcome (dependent on the stimulus presentes [CS+, CS-] \n",
    "    # we us if statement (switch in theano)\n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "    \n",
    "    # we use the same idea to get the associability per trial\n",
    "    assoc = tt.set_subtensor(assoc[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                alpha[tt.arange(n_subj),1], alpha[tt.arange(n_subj),0])))\n",
    "    \n",
    "    return Qs, vec, alpha, assoc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de4012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rouhani et al. version https://elifesciences.org/articles/61077\n",
    "# generate functions to run\n",
    "def update_Q_r(stim, shock,\n",
    "             Qs,vec,\n",
    "             eta,kappa,n_subj):\n",
    "    \"\"\"\n",
    "    This function updates the Q table according to Hybrid PH model\n",
    "    For information, please see this paper: https://www.sciencedirect.com/science/article/pii/S0896627316305840?via%3Dihub\n",
    "  \n",
    "    \"\"\"\n",
    "      \n",
    "    delta = shock - Qs[tt.arange(n_subj), stim]\n",
    "    alpha = eta + (kappa * abs(delta))\n",
    "    alpha = 1 / (1 + pm.math.exp(-alpha)) # sigmoid function\n",
    "    Qs = tt.set_subtensor(Qs[tt.arange(n_subj),stim], Qs[tt.arange(n_subj),stim] + alpha * delta)\n",
    "    \n",
    "  \n",
    "    vec = tt.set_subtensor(vec[tt.arange(n_subj),0], (tt.switch(tt.eq(stim,1), \n",
    "                                                                Qs[tt.arange(n_subj),1], Qs[tt.arange(n_subj),0])))\n",
    "        \n",
    "    return Qs, vec, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [eps, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='11255' class='' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      93.79% [11255/12000 50:42<03:21 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as model_B:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = .5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = .5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj]\n",
    "    \n",
    "    learn = pm.Normal('learn', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_b = pm.sample(tune=2000, draws=1000, return_inferencedata=True, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb238a8-005f-422d-bbca-54d7a147bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with intercept\n",
    "with pm.Model() as model_B_I:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = .5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = .5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept\n",
    "    \n",
    "    learn = pm.Normal('learn', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_i = pm.sample(tune=2000, draws=1000, return_inferencedata=True, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bbfd10-7229-4a13-b3a6-473e50cee83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with random intercept\n",
    "with pm.Model() as model_B_r_I:\n",
    "    \n",
    "   # betaHyper= pm.Normal('betaH', 0, 1)\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    alpha = pm.Beta('alpha', 1,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 5, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = .5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = .5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "    \n",
    "    vec_ = vec[trials,subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    learn = pm.Normal('learn', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_ri = pm.sample(tune=3000, draws=2000, return_inferencedata=True, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddbe8f",
   "metadata": {},
   "source": [
    "## Hierarchal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd609241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try alpha as beta distribution\n",
    "with pm.Model() as model_H:\n",
    "    \n",
    "    # intercept\n",
    "    mu = pm.Normal('mu', 0, 1)\n",
    "    sd = pm.HalfNormal('sd',5) \n",
    "    intercept_matt = pm.Normal('intercept_matt', mu=0, sd=1, shape=n_subj)\n",
    "    intercept = pm.Deterministic('intercept',intercept_matt + mu*sd)\n",
    "    \n",
    "    phi = pm.Uniform(\"phi\", lower=0.0, upper=1.0)\n",
    "\n",
    "    kappa_log = pm.Exponential(\"kappa_log\", lam=1.5)\n",
    "    kappa = pm.Deterministic(\"kappa\", tt.exp(kappa_log))\n",
    "\n",
    "    alpha = pm.Beta(\"alpha\", alpha=phi * kappa, beta=(1.0 - phi) * kappa, shape=n_subj)\n",
    "    \n",
    "    \n",
    "    beta_h = pm.Normal('beta_h', 0,1)\n",
    "    beta_sd = pm.HalfNormal('beta_sd', 1)\n",
    "    beta = pm.Normal('beta',beta_h, beta_sd, shape=n_subj)\n",
    "       \n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    Qs = .5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec0 = .5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec], updates = theano.scan(\n",
    "        fn=update_Q,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec0],\n",
    "        non_sequences=[alpha, n_subj])\n",
    "   \n",
    "     \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    learn = pm.Normal('learn', vec_, eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_hB = pm.sample(tune=3000, draws=2000, return_inferencedata=True, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e23171",
   "metadata": {},
   "source": [
    "# The Pearce-Hall Hybrid model\n",
    "\n",
    "This is an attempt to build the PH Hybrid model.</br>\n",
    "This model doesn't assume a simple constant learning rate (as the RW), rather, it incorporated both a constant learning rate and a dynamic one. </br>\n",
    "The dynamic one is being updated by the amount of new information given.</br> \n",
    "The model goes like that: </br>\n",
    "(1) Vi(k+1) = Vi (k) + κα(k)δ </br>\n",
    "(2) δ = reward - Vi(k) </br>\n",
    "(3) α(k+1) = η|δ|+(1-η)α(k)</br>\n",
    "\n",
    "So the current value is an update of the previous one plus a constant learning rate (kappa) and an associability weight (α) (times the δ = prediction error). </br> \n",
    "The α is set by a constant weight of associability (η) and the previous α.\n",
    "\n",
    "\n",
    "So now, our updating function will include those elements as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_PH:\n",
    "  \n",
    "      \n",
    "    eta = pm.Beta('eta', 2,2, shape=n_subj)\n",
    "    kappa = pm.Beta('kappa', 2,2, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    # intercept\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    alpha = 0 * tt.ones((n_subj,2), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    assoc = 0 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec, alpha, assoc], updates = theano.scan(\n",
    "        fn=update_Q_hall,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec, alpha, assoc],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    learn = pm.Normal('learn', mu = vec_, sd = eps, observed=rating) \n",
    "    \n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_ph = pm.sample(tune=3000, draws=2000, return_inferencedata=True, target_accept=0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba040b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_PH_h:\n",
    "    \n",
    "    # Hyper priors\n",
    "    eta_a = pm.TruncatedNormal('eta_a', 1, 1, lower = 0.3)\n",
    "    eta_b = pm.TruncatedNormal('eta_b', 1, 1, lower = 0.3)\n",
    "    \n",
    "    kappa_a = pm.TruncatedNormal('kappa_a', 1, 1, lower = 0.3)\n",
    "    kappa_b = pm.TruncatedNormal('kappa_b', 1, 1, lower = 0.3)\n",
    "      \n",
    "    eta = pm.Beta('eta', eta_a, eta_b, shape=n_subj)\n",
    "    kappa = pm.Beta('kappa', kappa_a, kappa_b, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    # intercept\n",
    "    intercept = pm.Normal('intercept', 0, 5, shape=n_subj)\n",
    "    \n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    alpha = 0 * tt.ones((n_subj,2), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    assoc = 0 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec, alpha, assoc], updates = theano.scan(\n",
    "        fn=update_Q_hall,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec, alpha, assoc],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj] + intercept[subj]\n",
    "    \n",
    "    learn = pm.Normal('learn', mu = vec_, sd = eps, observed=rating) \n",
    "    \n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    \n",
    "    tr_ph_h = pm.sample(tune=3000, draws=2000, return_inferencedata=True, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_PH_R:\n",
    "  \n",
    "      \n",
    "    eta = pm.Normal('eta', 0,1, shape=n_subj)\n",
    "    kappa = pm.Normal('kappa', 0,1, shape=n_subj)\n",
    "    beta = pm.Normal('beta',0, 1, shape=n_subj)\n",
    "    eps = pm.HalfNormal('eps', 5)\n",
    "    \n",
    "    # intercept\n",
    "    #intercept = pm.Normal('intercept', 0, .5, shape=n_subj)\n",
    "    \n",
    "    Qs = 0.5 * tt.ones((n_subj,2), dtype='float64') # set values for boths stimuli (CS+, CS-)\n",
    "    vec = 0.5 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "  #  alpha = 0 * tt.ones((n_subj,2), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "   # assoc = 0 * tt.ones((n_subj,1), dtype='float64') # vector to save the relevant stimulus's expactation\n",
    "    \n",
    "    [Qs,vec, alpha], updates = theano.scan(\n",
    "        fn=update_Q_r,\n",
    "        sequences=[stim, reward],\n",
    "        outputs_info=[Qs, vec, None],\n",
    "        non_sequences=[eta, kappa, n_subj])\n",
    "    \n",
    "    vec_ = vec[trials, subj,0] * beta[subj]# + intercept[subj]\n",
    "    \n",
    "    learn = pm.Normal('learn', mu = vec_, sd = eps, observed=rating) \n",
    "    \n",
    "    # add matrix of expected values (trials X subjects)\n",
    "    ev = pm.Deterministic('expected_value', vec_)\n",
    "    # add associability\n",
    "   # alpha = pm.Deterministic('pe', alpha)\n",
    "    \n",
    "    tr_ph_r = pm.sample(tune=3000, draws=2000, return_inferencedata=True, target_accept=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b224f3",
   "metadata": {},
   "source": [
    "## model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = az.compare({'basic model': tr_b, 'Model with intercept':tr_i, 'Model with random intercept':tr_ri, 'Hierarchical model': tr_hB, 'Pearce-Hall':tr_ph, 'Pearce-Hall Rouani': tr_ph_r,'Hierarchical Pearce-Hall':tr_ph_h}, ic='loo')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b706a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = db[['sub','age', 'gender', 'moca_score']].sort_values('sub').drop_duplicates().reset_index(drop=True)\n",
    "learning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = az.summary(tr_hB, var_names=['alpha'])[['mean']]\n",
    "kappa = az.summary(tr_ph_h, var_names=['kappa'])[['mean']]\n",
    "eta = az.summary(tr_ph_h, var_names=['eta'])[['mean']]\n",
    "\n",
    "alpha = alpha.rename(columns={'mean': \"alpha\"}).reset_index(drop=True)\n",
    "kappa = kappa.rename(columns={'mean': \"kappa\"}).reset_index(drop=True)\n",
    "eta   =   eta.rename(columns={'mean': \"eta\"}).reset_index(drop=True)\n",
    "\n",
    "learning = learning.merge(alpha, left_index=True, right_index=True)\n",
    "learning = learning.merge(kappa, left_index=True, right_index=True)\n",
    "learning = learning.merge(eta, left_index=True, right_index=True)\n",
    "\n",
    "learning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(df):\n",
    "    with pm.Model() as RR:\n",
    "\n",
    "        a = pm.Normal('intercept', 0, 1)\n",
    "        b = pm.Normal('slope', 0, 1)\n",
    "        eps = pm.Exponential('eps', 1)\n",
    "        y_hat = a + b*df.x\n",
    "\n",
    "        nu = pm.InverseGamma(\"nu\", alpha=3, beta=1)\n",
    "\n",
    "        #likelihood = pm.Normal(\"likelihood\", mu=y_hat, sigma=eps, observed=y)\n",
    "\n",
    "        likelihood = pm.StudentT(\n",
    "            \"likelihood\", mu=y_hat, sigma=eps, nu=nu, observed=df.y\n",
    "        )\n",
    "\n",
    "        trace_robust = pm.sample(tune=3000, draws=1000, return_inferencedata=True, target_accept=0.95)\n",
    "        \n",
    "    return(trace_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707aafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_corr = corr(pd.DataFrame({'x': learning.age/100, 'y': learning.alpha}).reset_index(drop=True))\n",
    "Kappa_corr = corr(pd.DataFrame({'x': learning.age/100, 'y': learning.kappa}).reset_index(drop=True))\n",
    "eta_corr   = corr(pd.DataFrame({'x': learning.age/100, 'y': learning.eta}).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a12cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = az.summary(alpha_corr, var_names=['slope','intercept'], hdi_prob=.89)[['mean','hdi_5.5%','hdi_94.5%']]\n",
    "kappa = az.summary(Kappa_corr, var_names=['slope','intercept'], hdi_prob=.89)[['mean','hdi_5.5%','hdi_94.5%']]\n",
    "eta = az.summary(eta_corr, var_names=['slope','intercept'], hdi_prob=.89)[['mean','hdi_5.5%','hdi_94.5%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sns.scatterplot(y = 'alpha',  x = 'age', data=learning, ax=axes[0])\n",
    "sns.scatterplot(y = 'kappa', x = 'age', data=learning, ax=axes[1])\n",
    "sns.scatterplot(y = 'eta', x = 'age', data=learning, ax=axes[2])\n",
    "\n",
    "sns.lineplot(learning.age,alpha['mean']['intercept']+alpha['mean']['slope']*learning.age/100, ax=axes[0])\n",
    "sns.lineplot(learning.age,kappa['mean']['intercept']+kappa['mean']['slope']*learning.age/100, ax=axes[1])\n",
    "sns.lineplot(learning.age,eta['mean']['intercept']+eta['mean']['slope']*learning.age/100, ax=axes[2])\n",
    "\n",
    "axes[0].set(ylim=(0,1))\n",
    "axes[1].set(ylim=(0,1))\n",
    "axes[2].set(ylim=(0,1))\n",
    "\n",
    "\n",
    "text = 'β = {:.2f},\\n89% HDPi [{:.2f}, {:.2f}]'.format(float(alpha['mean']['slope']),\n",
    "                                                        float(alpha['hdi_5.5%']['slope']),\n",
    "                                                        float(alpha['hdi_94.5%']['slope']))\n",
    "axes[0].text(20, .9, text, fontsize=12)\n",
    "\n",
    "text = 'β = {:.2f},\\n89% HDPi [{:.2f}, {:.2f}]'.format(float(kappa['mean']['slope']),\n",
    "                                                        float(kappa['hdi_5.5%']['slope']),\n",
    "                                                        float(kappa['hdi_94.5%']['slope']))\n",
    "axes[1].text(20, .9, text, fontsize=10)\n",
    "\n",
    "text = 'β = {:.2f},\\n89% HDPi [{:.2f}, {:.2f}]'.format(float(eta['mean']['slope']),\n",
    "                                                        float(eta['hdi_5.5%']['slope']),\n",
    "                                                        float(eta['hdi_94.5%']['slope']))\n",
    "axes[2].text(20, .9, text, fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.to_csv('data/reversal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
